{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"resnet50_48x48.C.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"CnzwnPKGJSRq","colab_type":"text"},"source":["# Tweaked ResNet50  for 48x48x1 inputs\n","\n","Made few chages in the first convolution and pooling layer of ResNet50 such that initial infomation loss is avoided for small (48x48) size input image\n","\n","References:  \n","&nbsp;&nbsp;\\[1\\] [Resnet with Keras](https://github.com/priya-dwivedi/Deep-Learning/blob/master/resnet_keras/Residual_Networks_yourself.ipynb)  \n","&nbsp;&nbsp;\\[2\\] [Kaggle Facial Expression DataSet](https://www.kaggle.com/c/challenges-in-representation-learning-facial-expression-recognition-challenge) is of grayscale 48x48 size images"]},{"cell_type":"code","metadata":{"id":"zrvnj3WyWmOw","colab_type":"code","outputId":"f076bd85-9534-4791-f1ee-0028219d54fd","executionInfo":{"status":"ok","timestamp":1565976689153,"user_tz":420,"elapsed":1556,"user":{"displayName":"Kilean Hwang","photoUrl":"","userId":"05193167569663589626"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["import numpy as np\n","import keras\n","regularizers = keras.regularizers\n","K = keras.backend"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"O5orxmYAJ4jK","colab_type":"text"},"source":["### Define Residual(=Identity) Bock"]},{"cell_type":"code","metadata":{"id":"gytYH5r9W0mz","colab_type":"code","colab":{}},"source":["def identity_block(X, f, filters, stage, block):\n","    \"\"\"\n","    Implementation of the identity block as defined in Figure 3\n","    \n","    Arguments:\n","    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n","    f -- integer, specifying the shape of the middle CONV's window for the main path\n","    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n","    stage -- integer, used to name the layers, depending on their position in the network\n","    block -- string/character, used to name the layers, depending on their position in the network\n","    \n","    Returns:\n","    X -- output of the identity block, tensor of shape (n_H, n_W, n_C)\n","    \"\"\"\n","    \n","    # defining name basis\n","    conv_name_base = 'res' + str(stage) + block + '_branch'\n","    bn_name_base = 'bn' + str(stage) + block + '_branch'\n","    \n","    # Retrieve Filters\n","    F1, F2, F3 = filters\n","    \n","    # Save the input value. You'll need this later to add back to the main path. \n","    X_shortcut = X\n","    \n","    # First component of main path\n","    X = keras.layers.Conv2D(filters = F1, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2a', \n","                            kernel_initializer = keras.initializers.glorot_uniform(seed=0))(X)\n","    X = keras.layers.BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n","    X = keras.layers.Activation('relu')(X)\n","\n","    # Second component of main path (≈3 lines)\n","    X = keras.layers.Conv2D(filters = F2, kernel_size = (f, f), strides = (1,1), padding = 'same', name = conv_name_base + '2b', \n","                            kernel_initializer = keras.initializers.glorot_uniform(seed=0))(X)\n","    X = keras.layers.BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n","    X = keras.layers.Activation('relu')(X)\n","\n","    # Third component of main path (≈2 lines)\n","    X = keras.layers.Conv2D(filters = F3, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2c', \n","                            kernel_initializer = keras.initializers.glorot_uniform(seed=0))(X)\n","    X = keras.layers.BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n","\n","\n","    # Final step: Add shortcut value to main path, and pass it through a RELU activation (≈2 lines)\n","    X = keras.layers.Add()([X, X_shortcut])\n","    X = keras.layers.Activation('relu')(X)\n","    \n","    \n","    return X"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"AV328DvMNlaf"},"source":["### Define Down-sampling(=Convolution) Bock"]},{"cell_type":"code","metadata":{"id":"qA4zR-P6XNjl","colab_type":"code","colab":{}},"source":["def convolutional_block(X, f, filters, stage, block, s = 2):\n","    \"\"\"\n","    Implementation of the convolutional block as defined in Figure 4\n","    \n","    Arguments:\n","    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n","    f -- integer, specifying the shape of the middle CONV's window for the main path\n","    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n","    stage -- integer, used to name the layers, depending on their position in the network\n","    block -- string/character, used to name the layers, depending on their position in the network\n","    s -- Integer, specifying the stride to be used\n","    \n","    Returns:\n","    X -- output of the convolutional block, tensor of shape (n_H, n_W, n_C)\n","    \"\"\"\n","    \n","    # defining name basis\n","    conv_name_base = 'res' + str(stage) + block + '_branch'\n","    bn_name_base = 'bn' + str(stage) + block + '_branch'\n","    \n","    # Retrieve Filters\n","    F1, F2, F3 = filters\n","    \n","    # Save the input value\n","    X_shortcut = X\n","\n","\n","    ##### MAIN PATH #####\n","    # First component of main path \n","    X = keras.layers.Conv2D(F1, (1, 1), strides = (1,1), name = conv_name_base + '2a', \n","                            kernel_initializer = keras.initializers.glorot_uniform(seed=0))(X)\n","    X = keras.layers.BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n","    X = keras.layers.Activation('relu')(X)\n","\n","    # Second component of main path (≈3 lines)\n","    X = keras.layers.Conv2D(filters = F2, kernel_size = (f, f), strides = (s,s), padding = 'same', name = conv_name_base + '2b', \n","                            kernel_initializer = keras.initializers.glorot_uniform(seed=0))(X)\n","    X = keras.layers.BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n","    X = keras.layers.Activation('relu')(X)\n","\n","\n","    # Third component of main path (≈2 lines)\n","    X = keras.layers.Conv2D(filters = F3, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2c', \n","                            kernel_initializer = keras.initializers.glorot_uniform(seed=0))(X)\n","    X = keras.layers.BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n","\n","\n","    ##### SHORTCUT PATH #### (≈2 lines)\n","    X_shortcut = keras.layers.Conv2D(filters = F3, kernel_size = (1, 1), strides = (s,s), padding = 'valid', name = conv_name_base + '1',\n","                        kernel_initializer = keras.initializers.glorot_uniform(seed=0))(X_shortcut)\n","    X_shortcut = keras.layers.BatchNormalization(axis = 3, name = bn_name_base + '1')(X_shortcut)\n","\n","    # Final step: Add shortcut value to main path, and pass it through a RELU activation (≈2 lines)\n","    X = keras.layers.Add()([X, X_shortcut])\n","    X = keras.layers.Activation('relu')(X)\n","    \n","    return X"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"74HTZZNZOrxo","colab_type":"text"},"source":["### Define ResNet50"]},{"cell_type":"code","metadata":{"id":"drJ13VdiiqmU","colab_type":"code","colab":{}},"source":["def get_resnet50_48x48(input_shape=(48, 48, 1), classes=7):\n","    \"\"\"\n","    Implementation of the popular ResNet50 the following architecture:\n","    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n","    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> TOPLAYER\n","\n","    Arguments:\n","    input_shape -- shape of the images of the dataset\n","    classes -- integer, number of classes\n","\n","    Returns:\n","    model -- a Model() instance in Keras\n","    \"\"\"\n","\n","    # Define the input as a tensor with shape input_shape\n","    X_input = keras.layers.Input(input_shape)\n","\n","    # Zero-Padding\n","    X = keras.layers.ZeroPadding2D((2, 2))(X_input)\n","\n","    # Stage 1\n","    X = keras.layers.Conv2D(64, (3, 3), strides=(1, 1), name='conv1a', \n","\t\t                        kernel_initializer=keras.initializers.glorot_uniform(seed=0))(X)\n","    X = keras.layers.BatchNormalization(axis = 3, name = 'bn_conv1a')(X)\n","    X = keras.layers.Activation('relu')(X)\n","    X = keras.layers.Conv2D(64, (3, 3), strides=(1, 1), name='conv1b', \n","\t\t                        kernel_initializer=keras.initializers.glorot_uniform(seed=0))(X)\n","    X = keras.layers.BatchNormalization(axis=3, name='bn_conv1b')(X)\n","    X = keras.layers.Activation('relu')(X)\t\n","    # X = keras.layers.ZeroPadding2D((1, 1))(X)\n","\n","\n","    # Stage 2\n","    X = convolutional_block(X, f=3, filters=[64, 64, 256], stage=2, block='a', s=1)\n","    X = identity_block(X, 3, [64, 64, 256], stage=2, block='b')\n","    X = identity_block(X, 3, [64, 64, 256], stage=2, block='c')\n","\n","    ### START CODE HERE ###\n","\n","    # Stage 3 (≈4 lines)\n","    X = convolutional_block(X, f = 3, filters = [128, 128, 512], stage = 3, block='a', s = 2)\n","    X = identity_block(X, 3, [128, 128, 512], stage=3, block='b')\n","    X = identity_block(X, 3, [128, 128, 512], stage=3, block='c')\n","    X = identity_block(X, 3, [128, 128, 512], stage=3, block='d')\n","\n","    # Stage 4 (≈6 lines)\n","    X = convolutional_block(X, f = 3, filters = [256, 256, 1024], stage = 4, block='a', s = 2)\n","    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='b')\n","    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='c')\n","    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='d')\n","    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='e')\n","    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='f')\n","\n","    # Stage 5 (≈3 lines)\n","    X = convolutional_block(X, f = 3, filters = [512, 512, 2048], stage = 5, block='a', s = 2)\n","    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='b')\n","    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='c')\n","\n","    # AVGPOOL (≈1 line). Use \"X = AveragePooling2D(...)(X)\"\n","    # X = keras.layers.AveragePooling2D((2,2), name=\"avg_pool\")(X)\n","    # X = keras.layers.GlobalAveragePooling2D(name=\"avg_pool\")(X)\n","\n","    ### END CODE HERE ###\n","\n","    # Create model\n","    model = keras.models.Model(inputs = X_input, outputs = X, name='resnet50_48x48')\n","\n","    return model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"DatH3IEafXZU","colab_type":"code","outputId":"4fd95c10-7d06-4d22-bcc2-e07e74f15f85","executionInfo":{"status":"ok","timestamp":1565976697743,"user_tz":420,"elapsed":10032,"user":{"displayName":"Kilean Hwang","photoUrl":"","userId":"05193167569663589626"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["resnet50_48x48 = get_resnet50_48x48()\n","resnet50_48x48.summary()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING: Logging before flag parsing goes to stderr.\n","W0816 17:31:29.088083 139952381024128 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","W0816 17:31:29.126052 139952381024128 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","W0816 17:31:29.135364 139952381024128 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n","W0816 17:31:29.169231 139952381024128 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n","\n","W0816 17:31:29.170135 139952381024128 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n","\n","W0816 17:31:32.166790 139952381024128 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            (None, 48, 48, 1)    0                                            \n","__________________________________________________________________________________________________\n","zero_padding2d_1 (ZeroPadding2D (None, 52, 52, 1)    0           input_1[0][0]                    \n","__________________________________________________________________________________________________\n","conv1a (Conv2D)                 (None, 50, 50, 64)   640         zero_padding2d_1[0][0]           \n","__________________________________________________________________________________________________\n","bn_conv1a (BatchNormalization)  (None, 50, 50, 64)   256         conv1a[0][0]                     \n","__________________________________________________________________________________________________\n","activation_1 (Activation)       (None, 50, 50, 64)   0           bn_conv1a[0][0]                  \n","__________________________________________________________________________________________________\n","conv1b (Conv2D)                 (None, 48, 48, 64)   36928       activation_1[0][0]               \n","__________________________________________________________________________________________________\n","bn_conv1b (BatchNormalization)  (None, 48, 48, 64)   256         conv1b[0][0]                     \n","__________________________________________________________________________________________________\n","activation_2 (Activation)       (None, 48, 48, 64)   0           bn_conv1b[0][0]                  \n","__________________________________________________________________________________________________\n","res2a_branch2a (Conv2D)         (None, 48, 48, 64)   4160        activation_2[0][0]               \n","__________________________________________________________________________________________________\n","bn2a_branch2a (BatchNormalizati (None, 48, 48, 64)   256         res2a_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_3 (Activation)       (None, 48, 48, 64)   0           bn2a_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res2a_branch2b (Conv2D)         (None, 48, 48, 64)   36928       activation_3[0][0]               \n","__________________________________________________________________________________________________\n","bn2a_branch2b (BatchNormalizati (None, 48, 48, 64)   256         res2a_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_4 (Activation)       (None, 48, 48, 64)   0           bn2a_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res2a_branch2c (Conv2D)         (None, 48, 48, 256)  16640       activation_4[0][0]               \n","__________________________________________________________________________________________________\n","res2a_branch1 (Conv2D)          (None, 48, 48, 256)  16640       activation_2[0][0]               \n","__________________________________________________________________________________________________\n","bn2a_branch2c (BatchNormalizati (None, 48, 48, 256)  1024        res2a_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","bn2a_branch1 (BatchNormalizatio (None, 48, 48, 256)  1024        res2a_branch1[0][0]              \n","__________________________________________________________________________________________________\n","add_1 (Add)                     (None, 48, 48, 256)  0           bn2a_branch2c[0][0]              \n","                                                                 bn2a_branch1[0][0]               \n","__________________________________________________________________________________________________\n","activation_5 (Activation)       (None, 48, 48, 256)  0           add_1[0][0]                      \n","__________________________________________________________________________________________________\n","res2b_branch2a (Conv2D)         (None, 48, 48, 64)   16448       activation_5[0][0]               \n","__________________________________________________________________________________________________\n","bn2b_branch2a (BatchNormalizati (None, 48, 48, 64)   256         res2b_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_6 (Activation)       (None, 48, 48, 64)   0           bn2b_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res2b_branch2b (Conv2D)         (None, 48, 48, 64)   36928       activation_6[0][0]               \n","__________________________________________________________________________________________________\n","bn2b_branch2b (BatchNormalizati (None, 48, 48, 64)   256         res2b_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_7 (Activation)       (None, 48, 48, 64)   0           bn2b_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res2b_branch2c (Conv2D)         (None, 48, 48, 256)  16640       activation_7[0][0]               \n","__________________________________________________________________________________________________\n","bn2b_branch2c (BatchNormalizati (None, 48, 48, 256)  1024        res2b_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","add_2 (Add)                     (None, 48, 48, 256)  0           bn2b_branch2c[0][0]              \n","                                                                 activation_5[0][0]               \n","__________________________________________________________________________________________________\n","activation_8 (Activation)       (None, 48, 48, 256)  0           add_2[0][0]                      \n","__________________________________________________________________________________________________\n","res2c_branch2a (Conv2D)         (None, 48, 48, 64)   16448       activation_8[0][0]               \n","__________________________________________________________________________________________________\n","bn2c_branch2a (BatchNormalizati (None, 48, 48, 64)   256         res2c_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_9 (Activation)       (None, 48, 48, 64)   0           bn2c_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res2c_branch2b (Conv2D)         (None, 48, 48, 64)   36928       activation_9[0][0]               \n","__________________________________________________________________________________________________\n","bn2c_branch2b (BatchNormalizati (None, 48, 48, 64)   256         res2c_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_10 (Activation)      (None, 48, 48, 64)   0           bn2c_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res2c_branch2c (Conv2D)         (None, 48, 48, 256)  16640       activation_10[0][0]              \n","__________________________________________________________________________________________________\n","bn2c_branch2c (BatchNormalizati (None, 48, 48, 256)  1024        res2c_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","add_3 (Add)                     (None, 48, 48, 256)  0           bn2c_branch2c[0][0]              \n","                                                                 activation_8[0][0]               \n","__________________________________________________________________________________________________\n","activation_11 (Activation)      (None, 48, 48, 256)  0           add_3[0][0]                      \n","__________________________________________________________________________________________________\n","res3a_branch2a (Conv2D)         (None, 48, 48, 128)  32896       activation_11[0][0]              \n","__________________________________________________________________________________________________\n","bn3a_branch2a (BatchNormalizati (None, 48, 48, 128)  512         res3a_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_12 (Activation)      (None, 48, 48, 128)  0           bn3a_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res3a_branch2b (Conv2D)         (None, 24, 24, 128)  147584      activation_12[0][0]              \n","__________________________________________________________________________________________________\n","bn3a_branch2b (BatchNormalizati (None, 24, 24, 128)  512         res3a_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_13 (Activation)      (None, 24, 24, 128)  0           bn3a_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res3a_branch2c (Conv2D)         (None, 24, 24, 512)  66048       activation_13[0][0]              \n","__________________________________________________________________________________________________\n","res3a_branch1 (Conv2D)          (None, 24, 24, 512)  131584      activation_11[0][0]              \n","__________________________________________________________________________________________________\n","bn3a_branch2c (BatchNormalizati (None, 24, 24, 512)  2048        res3a_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","bn3a_branch1 (BatchNormalizatio (None, 24, 24, 512)  2048        res3a_branch1[0][0]              \n","__________________________________________________________________________________________________\n","add_4 (Add)                     (None, 24, 24, 512)  0           bn3a_branch2c[0][0]              \n","                                                                 bn3a_branch1[0][0]               \n","__________________________________________________________________________________________________\n","activation_14 (Activation)      (None, 24, 24, 512)  0           add_4[0][0]                      \n","__________________________________________________________________________________________________\n","res3b_branch2a (Conv2D)         (None, 24, 24, 128)  65664       activation_14[0][0]              \n","__________________________________________________________________________________________________\n","bn3b_branch2a (BatchNormalizati (None, 24, 24, 128)  512         res3b_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_15 (Activation)      (None, 24, 24, 128)  0           bn3b_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res3b_branch2b (Conv2D)         (None, 24, 24, 128)  147584      activation_15[0][0]              \n","__________________________________________________________________________________________________\n","bn3b_branch2b (BatchNormalizati (None, 24, 24, 128)  512         res3b_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_16 (Activation)      (None, 24, 24, 128)  0           bn3b_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res3b_branch2c (Conv2D)         (None, 24, 24, 512)  66048       activation_16[0][0]              \n","__________________________________________________________________________________________________\n","bn3b_branch2c (BatchNormalizati (None, 24, 24, 512)  2048        res3b_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","add_5 (Add)                     (None, 24, 24, 512)  0           bn3b_branch2c[0][0]              \n","                                                                 activation_14[0][0]              \n","__________________________________________________________________________________________________\n","activation_17 (Activation)      (None, 24, 24, 512)  0           add_5[0][0]                      \n","__________________________________________________________________________________________________\n","res3c_branch2a (Conv2D)         (None, 24, 24, 128)  65664       activation_17[0][0]              \n","__________________________________________________________________________________________________\n","bn3c_branch2a (BatchNormalizati (None, 24, 24, 128)  512         res3c_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_18 (Activation)      (None, 24, 24, 128)  0           bn3c_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res3c_branch2b (Conv2D)         (None, 24, 24, 128)  147584      activation_18[0][0]              \n","__________________________________________________________________________________________________\n","bn3c_branch2b (BatchNormalizati (None, 24, 24, 128)  512         res3c_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_19 (Activation)      (None, 24, 24, 128)  0           bn3c_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res3c_branch2c (Conv2D)         (None, 24, 24, 512)  66048       activation_19[0][0]              \n","__________________________________________________________________________________________________\n","bn3c_branch2c (BatchNormalizati (None, 24, 24, 512)  2048        res3c_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","add_6 (Add)                     (None, 24, 24, 512)  0           bn3c_branch2c[0][0]              \n","                                                                 activation_17[0][0]              \n","__________________________________________________________________________________________________\n","activation_20 (Activation)      (None, 24, 24, 512)  0           add_6[0][0]                      \n","__________________________________________________________________________________________________\n","res3d_branch2a (Conv2D)         (None, 24, 24, 128)  65664       activation_20[0][0]              \n","__________________________________________________________________________________________________\n","bn3d_branch2a (BatchNormalizati (None, 24, 24, 128)  512         res3d_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_21 (Activation)      (None, 24, 24, 128)  0           bn3d_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res3d_branch2b (Conv2D)         (None, 24, 24, 128)  147584      activation_21[0][0]              \n","__________________________________________________________________________________________________\n","bn3d_branch2b (BatchNormalizati (None, 24, 24, 128)  512         res3d_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_22 (Activation)      (None, 24, 24, 128)  0           bn3d_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res3d_branch2c (Conv2D)         (None, 24, 24, 512)  66048       activation_22[0][0]              \n","__________________________________________________________________________________________________\n","bn3d_branch2c (BatchNormalizati (None, 24, 24, 512)  2048        res3d_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","add_7 (Add)                     (None, 24, 24, 512)  0           bn3d_branch2c[0][0]              \n","                                                                 activation_20[0][0]              \n","__________________________________________________________________________________________________\n","activation_23 (Activation)      (None, 24, 24, 512)  0           add_7[0][0]                      \n","__________________________________________________________________________________________________\n","res4a_branch2a (Conv2D)         (None, 24, 24, 256)  131328      activation_23[0][0]              \n","__________________________________________________________________________________________________\n","bn4a_branch2a (BatchNormalizati (None, 24, 24, 256)  1024        res4a_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_24 (Activation)      (None, 24, 24, 256)  0           bn4a_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res4a_branch2b (Conv2D)         (None, 12, 12, 256)  590080      activation_24[0][0]              \n","__________________________________________________________________________________________________\n","bn4a_branch2b (BatchNormalizati (None, 12, 12, 256)  1024        res4a_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_25 (Activation)      (None, 12, 12, 256)  0           bn4a_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res4a_branch2c (Conv2D)         (None, 12, 12, 1024) 263168      activation_25[0][0]              \n","__________________________________________________________________________________________________\n","res4a_branch1 (Conv2D)          (None, 12, 12, 1024) 525312      activation_23[0][0]              \n","__________________________________________________________________________________________________\n","bn4a_branch2c (BatchNormalizati (None, 12, 12, 1024) 4096        res4a_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","bn4a_branch1 (BatchNormalizatio (None, 12, 12, 1024) 4096        res4a_branch1[0][0]              \n","__________________________________________________________________________________________________\n","add_8 (Add)                     (None, 12, 12, 1024) 0           bn4a_branch2c[0][0]              \n","                                                                 bn4a_branch1[0][0]               \n","__________________________________________________________________________________________________\n","activation_26 (Activation)      (None, 12, 12, 1024) 0           add_8[0][0]                      \n","__________________________________________________________________________________________________\n","res4b_branch2a (Conv2D)         (None, 12, 12, 256)  262400      activation_26[0][0]              \n","__________________________________________________________________________________________________\n","bn4b_branch2a (BatchNormalizati (None, 12, 12, 256)  1024        res4b_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_27 (Activation)      (None, 12, 12, 256)  0           bn4b_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res4b_branch2b (Conv2D)         (None, 12, 12, 256)  590080      activation_27[0][0]              \n","__________________________________________________________________________________________________\n","bn4b_branch2b (BatchNormalizati (None, 12, 12, 256)  1024        res4b_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_28 (Activation)      (None, 12, 12, 256)  0           bn4b_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res4b_branch2c (Conv2D)         (None, 12, 12, 1024) 263168      activation_28[0][0]              \n","__________________________________________________________________________________________________\n","bn4b_branch2c (BatchNormalizati (None, 12, 12, 1024) 4096        res4b_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","add_9 (Add)                     (None, 12, 12, 1024) 0           bn4b_branch2c[0][0]              \n","                                                                 activation_26[0][0]              \n","__________________________________________________________________________________________________\n","activation_29 (Activation)      (None, 12, 12, 1024) 0           add_9[0][0]                      \n","__________________________________________________________________________________________________\n","res4c_branch2a (Conv2D)         (None, 12, 12, 256)  262400      activation_29[0][0]              \n","__________________________________________________________________________________________________\n","bn4c_branch2a (BatchNormalizati (None, 12, 12, 256)  1024        res4c_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_30 (Activation)      (None, 12, 12, 256)  0           bn4c_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res4c_branch2b (Conv2D)         (None, 12, 12, 256)  590080      activation_30[0][0]              \n","__________________________________________________________________________________________________\n","bn4c_branch2b (BatchNormalizati (None, 12, 12, 256)  1024        res4c_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_31 (Activation)      (None, 12, 12, 256)  0           bn4c_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res4c_branch2c (Conv2D)         (None, 12, 12, 1024) 263168      activation_31[0][0]              \n","__________________________________________________________________________________________________\n","bn4c_branch2c (BatchNormalizati (None, 12, 12, 1024) 4096        res4c_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","add_10 (Add)                    (None, 12, 12, 1024) 0           bn4c_branch2c[0][0]              \n","                                                                 activation_29[0][0]              \n","__________________________________________________________________________________________________\n","activation_32 (Activation)      (None, 12, 12, 1024) 0           add_10[0][0]                     \n","__________________________________________________________________________________________________\n","res4d_branch2a (Conv2D)         (None, 12, 12, 256)  262400      activation_32[0][0]              \n","__________________________________________________________________________________________________\n","bn4d_branch2a (BatchNormalizati (None, 12, 12, 256)  1024        res4d_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_33 (Activation)      (None, 12, 12, 256)  0           bn4d_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res4d_branch2b (Conv2D)         (None, 12, 12, 256)  590080      activation_33[0][0]              \n","__________________________________________________________________________________________________\n","bn4d_branch2b (BatchNormalizati (None, 12, 12, 256)  1024        res4d_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_34 (Activation)      (None, 12, 12, 256)  0           bn4d_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res4d_branch2c (Conv2D)         (None, 12, 12, 1024) 263168      activation_34[0][0]              \n","__________________________________________________________________________________________________\n","bn4d_branch2c (BatchNormalizati (None, 12, 12, 1024) 4096        res4d_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","add_11 (Add)                    (None, 12, 12, 1024) 0           bn4d_branch2c[0][0]              \n","                                                                 activation_32[0][0]              \n","__________________________________________________________________________________________________\n","activation_35 (Activation)      (None, 12, 12, 1024) 0           add_11[0][0]                     \n","__________________________________________________________________________________________________\n","res4e_branch2a (Conv2D)         (None, 12, 12, 256)  262400      activation_35[0][0]              \n","__________________________________________________________________________________________________\n","bn4e_branch2a (BatchNormalizati (None, 12, 12, 256)  1024        res4e_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_36 (Activation)      (None, 12, 12, 256)  0           bn4e_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res4e_branch2b (Conv2D)         (None, 12, 12, 256)  590080      activation_36[0][0]              \n","__________________________________________________________________________________________________\n","bn4e_branch2b (BatchNormalizati (None, 12, 12, 256)  1024        res4e_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_37 (Activation)      (None, 12, 12, 256)  0           bn4e_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res4e_branch2c (Conv2D)         (None, 12, 12, 1024) 263168      activation_37[0][0]              \n","__________________________________________________________________________________________________\n","bn4e_branch2c (BatchNormalizati (None, 12, 12, 1024) 4096        res4e_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","add_12 (Add)                    (None, 12, 12, 1024) 0           bn4e_branch2c[0][0]              \n","                                                                 activation_35[0][0]              \n","__________________________________________________________________________________________________\n","activation_38 (Activation)      (None, 12, 12, 1024) 0           add_12[0][0]                     \n","__________________________________________________________________________________________________\n","res4f_branch2a (Conv2D)         (None, 12, 12, 256)  262400      activation_38[0][0]              \n","__________________________________________________________________________________________________\n","bn4f_branch2a (BatchNormalizati (None, 12, 12, 256)  1024        res4f_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_39 (Activation)      (None, 12, 12, 256)  0           bn4f_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res4f_branch2b (Conv2D)         (None, 12, 12, 256)  590080      activation_39[0][0]              \n","__________________________________________________________________________________________________\n","bn4f_branch2b (BatchNormalizati (None, 12, 12, 256)  1024        res4f_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_40 (Activation)      (None, 12, 12, 256)  0           bn4f_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res4f_branch2c (Conv2D)         (None, 12, 12, 1024) 263168      activation_40[0][0]              \n","__________________________________________________________________________________________________\n","bn4f_branch2c (BatchNormalizati (None, 12, 12, 1024) 4096        res4f_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","add_13 (Add)                    (None, 12, 12, 1024) 0           bn4f_branch2c[0][0]              \n","                                                                 activation_38[0][0]              \n","__________________________________________________________________________________________________\n","activation_41 (Activation)      (None, 12, 12, 1024) 0           add_13[0][0]                     \n","__________________________________________________________________________________________________\n","res5a_branch2a (Conv2D)         (None, 12, 12, 512)  524800      activation_41[0][0]              \n","__________________________________________________________________________________________________\n","bn5a_branch2a (BatchNormalizati (None, 12, 12, 512)  2048        res5a_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_42 (Activation)      (None, 12, 12, 512)  0           bn5a_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res5a_branch2b (Conv2D)         (None, 6, 6, 512)    2359808     activation_42[0][0]              \n","__________________________________________________________________________________________________\n","bn5a_branch2b (BatchNormalizati (None, 6, 6, 512)    2048        res5a_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_43 (Activation)      (None, 6, 6, 512)    0           bn5a_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res5a_branch2c (Conv2D)         (None, 6, 6, 2048)   1050624     activation_43[0][0]              \n","__________________________________________________________________________________________________\n","res5a_branch1 (Conv2D)          (None, 6, 6, 2048)   2099200     activation_41[0][0]              \n","__________________________________________________________________________________________________\n","bn5a_branch2c (BatchNormalizati (None, 6, 6, 2048)   8192        res5a_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","bn5a_branch1 (BatchNormalizatio (None, 6, 6, 2048)   8192        res5a_branch1[0][0]              \n","__________________________________________________________________________________________________\n","add_14 (Add)                    (None, 6, 6, 2048)   0           bn5a_branch2c[0][0]              \n","                                                                 bn5a_branch1[0][0]               \n","__________________________________________________________________________________________________\n","activation_44 (Activation)      (None, 6, 6, 2048)   0           add_14[0][0]                     \n","__________________________________________________________________________________________________\n","res5b_branch2a (Conv2D)         (None, 6, 6, 512)    1049088     activation_44[0][0]              \n","__________________________________________________________________________________________________\n","bn5b_branch2a (BatchNormalizati (None, 6, 6, 512)    2048        res5b_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_45 (Activation)      (None, 6, 6, 512)    0           bn5b_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res5b_branch2b (Conv2D)         (None, 6, 6, 512)    2359808     activation_45[0][0]              \n","__________________________________________________________________________________________________\n","bn5b_branch2b (BatchNormalizati (None, 6, 6, 512)    2048        res5b_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_46 (Activation)      (None, 6, 6, 512)    0           bn5b_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res5b_branch2c (Conv2D)         (None, 6, 6, 2048)   1050624     activation_46[0][0]              \n","__________________________________________________________________________________________________\n","bn5b_branch2c (BatchNormalizati (None, 6, 6, 2048)   8192        res5b_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","add_15 (Add)                    (None, 6, 6, 2048)   0           bn5b_branch2c[0][0]              \n","                                                                 activation_44[0][0]              \n","__________________________________________________________________________________________________\n","activation_47 (Activation)      (None, 6, 6, 2048)   0           add_15[0][0]                     \n","__________________________________________________________________________________________________\n","res5c_branch2a (Conv2D)         (None, 6, 6, 512)    1049088     activation_47[0][0]              \n","__________________________________________________________________________________________________\n","bn5c_branch2a (BatchNormalizati (None, 6, 6, 512)    2048        res5c_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_48 (Activation)      (None, 6, 6, 512)    0           bn5c_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res5c_branch2b (Conv2D)         (None, 6, 6, 512)    2359808     activation_48[0][0]              \n","__________________________________________________________________________________________________\n","bn5c_branch2b (BatchNormalizati (None, 6, 6, 512)    2048        res5c_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_49 (Activation)      (None, 6, 6, 512)    0           bn5c_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res5c_branch2c (Conv2D)         (None, 6, 6, 2048)   1050624     activation_49[0][0]              \n","__________________________________________________________________________________________________\n","bn5c_branch2c (BatchNormalizati (None, 6, 6, 2048)   8192        res5c_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","add_16 (Add)                    (None, 6, 6, 2048)   0           bn5c_branch2c[0][0]              \n","                                                                 activation_47[0][0]              \n","__________________________________________________________________________________________________\n","activation_50 (Activation)      (None, 6, 6, 2048)   0           add_16[0][0]                     \n","==================================================================================================\n","Total params: 23,616,064\n","Trainable params: 23,562,816\n","Non-trainable params: 53,248\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Rl1U6DMkfart","colab_type":"code","colab":{}},"source":["# model = keras.applications.resnet50.ResNet50(weights='imagenet')\n","# model.summary()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2DaCeaD4eth8","colab_type":"text"},"source":["### Add subnet for classification"]},{"cell_type":"code","metadata":{"id":"-RkLvpnR2YsV","colab_type":"code","outputId":"9c5cc2de-8e87-43e5-c28a-22cb7ca8a283","executionInfo":{"status":"ok","timestamp":1565976701530,"user_tz":420,"elapsed":13698,"user":{"displayName":"Kilean Hwang","photoUrl":"","userId":"05193167569663589626"}},"colab":{"base_uri":"https://localhost:8080/","height":613}},"source":["model = keras.models.Sequential()\n","model.add(resnet50_48x48)\n","model.add(keras.layers.GlobalAveragePooling2D(name='global_ave_pool'))\n","model.add(keras.layers.Dense(units=2048,name='FC1'))\n","model.add(keras.layers.BatchNormalization())\n","model.add(keras.layers.Activation('relu'))\n","model.add(keras.layers.Dropout(0.25))\n","model.add(keras.layers.Dense(units=128,name='FC2'))\n","model.add(keras.layers.BatchNormalization())\n","model.add(keras.layers.Activation('relu'))\n","model.add(keras.layers.Dropout(0.25))\n","model.add(keras.layers.Dense(7, activation='softmax'))\n","model.summary()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["W0816 17:31:40.738307 139952381024128 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"],"name":"stderr"},{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","resnet50_48x48 (Model)       (None, 6, 6, 2048)        23616064  \n","_________________________________________________________________\n","global_ave_pool (GlobalAvera (None, 2048)              0         \n","_________________________________________________________________\n","FC1 (Dense)                  (None, 2048)              4196352   \n","_________________________________________________________________\n","batch_normalization_1 (Batch (None, 2048)              8192      \n","_________________________________________________________________\n","activation_51 (Activation)   (None, 2048)              0         \n","_________________________________________________________________\n","dropout_1 (Dropout)          (None, 2048)              0         \n","_________________________________________________________________\n","FC2 (Dense)                  (None, 128)               262272    \n","_________________________________________________________________\n","batch_normalization_2 (Batch (None, 128)               512       \n","_________________________________________________________________\n","activation_52 (Activation)   (None, 128)               0         \n","_________________________________________________________________\n","dropout_2 (Dropout)          (None, 128)               0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 7)                 903       \n","=================================================================\n","Total params: 28,084,295\n","Trainable params: 28,026,695\n","Non-trainable params: 57,600\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"tWz2B8fzfU7y","colab_type":"code","colab":{}},"source":["# model.add(keras.layers.Conv2D(filters=256),kernal_size=(3,3),name='classification_conv1')\n","# model.add(keras.layers.Activation('relu'))\n","# model.add(keras.layers.Conv2D(filters=256),kernal_size=(3,3),name='classification_conv2')\n","# model.add(keras.layers.Activation('relu'))\n","# model.add(keras.layers.Conv2D(filters=256),kernal_size=(3,3),name='classification_conv3')\n","# model.add(keras.layers.Activation('relu'))\n","# model.add(keras.layers.Conv2D(filters=256),kernal_size=(3,3),name='classification_conv4')\n","# model.add(keras.layers.Activation('relu'))\n","# model.add(keras.layers.Conv2D(filters=7*9),kernal_size=(3,3),name='classification_conv5')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GUux0axyeIy9","colab_type":"text"},"source":["### Load Dataset"]},{"cell_type":"code","metadata":{"id":"lnpLsLF0ejf9","colab_type":"code","outputId":"e70e2679-8fd8-42cc-a741-ee69e36a0c2f","executionInfo":{"status":"ok","timestamp":1565976730649,"user_tz":420,"elapsed":42761,"user":{"displayName":"Kilean Hwang","photoUrl":"","userId":"05193167569663589626"}},"colab":{"base_uri":"https://localhost:8080/","height":127}},"source":["from google.colab import drive\n","drive.mount('/content/drive/', force_remount=True)\n","data_path = '/content/drive/My Drive/Colab Notebooks/data/'"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SNyPSKsIeNNA","colab_type":"code","colab":{}},"source":["import pickle\n","with open(data_path+'FER2013.train_data.pickle','rb') as f:\n","  train_data = pickle.load(f)\n","with open(data_path+'FER2013.public_test_data.pickle','rb') as f:\n","  public_test_data = pickle.load(f)\n","with open(data_path+'FER2013.private_test_data.pickle','rb') as f:\n","  private_test_data = pickle.load(f)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"F7UMj4wVuGij","colab_type":"code","colab":{}},"source":["sample_count = len(train_data['y'])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"m5KBNYTbrjIe","colab_type":"text"},"source":["### Cos decay with warm-up"]},{"cell_type":"code","metadata":{"id":"9b8f5hRYrtdR","colab_type":"code","colab":{}},"source":["base_batch_size = 256\n","base_lr = 0.02\n","multiplier = 0.5\n","batch_size = int(base_batch_size * multiplier)\n","initial_lr = base_lr * multiplier\n","warmup_epoch = 4\n","epochs = 40"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"O3lXXDWmrg6u","colab_type":"code","colab":{}},"source":["def cosine_decay_with_warmup(global_step,\n","                             learning_rate_base,\n","                             total_steps,\n","                             warmup_learning_rate=0.0,\n","                             warmup_steps=0,\n","                             hold_base_rate_steps=0,\n","                             learning_rate_min = 0.0001): \n","    \"\"\"Cosine decay schedule with warm up period.\n","\n","    Cosine annealing learning rate as described in:\n","      Loshchilov and Hutter, SGDR: Stochastic Gradient Descent with Warm Restarts.\n","      ICLR 2017. https://arxiv.org/abs/1608.03983\n","    In this schedule, the learning rate grows linearly from warmup_learning_rate\n","    to learning_rate_base for warmup_steps, then transitions to a cosine decay\n","    schedule.\n","\n","    Arguments:\n","        global_step {int} -- global step.\n","        learning_rate_base {float} -- base learning rate.\n","        total_steps {int} -- total number of training steps.\n","\n","    Keyword Arguments:\n","        warmup_learning_rate {float} -- initial learning rate for warm up. (default: {0.0})\n","        warmup_steps {int} -- number of warmup steps. (default: {0})\n","        hold_base_rate_steps {int} -- Optional number of steps to hold base learning rate\n","                                    before decaying. (default: {0})\n","    Returns:\n","      a float representing learning rate.\n","\n","    Raises:\n","      ValueError: if warmup_learning_rate is larger than learning_rate_base,\n","        or if warmup_steps is larger than total_steps.\n","    \"\"\"\n","\n","    if total_steps < warmup_steps:\n","        raise ValueError('total_steps must be larger or equal to '\n","                         'warmup_steps.')\n","    learning_rate = 0.5 * learning_rate_base * (1 + np.cos(\n","        np.pi *\n","        (global_step - warmup_steps - hold_base_rate_steps\n","         ) / float(total_steps - warmup_steps - hold_base_rate_steps))) + learning_rate_min\n","    if hold_base_rate_steps > 0:\n","        learning_rate = np.where(global_step > warmup_steps + hold_base_rate_steps,\n","                                 learning_rate, learning_rate_base)\n","    if warmup_steps > 0:\n","        if learning_rate_base + learning_rate_min < warmup_learning_rate:\n","            raise ValueError('learning_rate_base + learning_rate_min must be larger or equal to '\n","                             'warmup_learning_rate.')\n","        slope = (learning_rate_base + learning_rate_min - warmup_learning_rate) / warmup_steps\n","        warmup_rate = slope * global_step + warmup_learning_rate\n","        learning_rate = np.where(global_step < warmup_steps, warmup_rate,\n","                                 learning_rate)\n","    return np.where(global_step > total_steps, learning_rate_min, learning_rate) # keep learing after fully decayed (Kilean)\n","\n","\n","\n","class WarmUpCosineDecayScheduler(keras.callbacks.Callback):\n","    \"\"\"Cosine decay with warmup learning rate scheduler\n","    \"\"\"\n","\n","    def __init__(self,\n","                 learning_rate_base,\n","                 total_steps,\n","                 global_step_init=0,\n","                 warmup_learning_rate=0.0,\n","                 warmup_steps=0,\n","                 hold_base_rate_steps=0,\n","                 verbose=0):\n","        \"\"\"Constructor for cosine decay with warmup learning rate scheduler.\n","\n","    Arguments:\n","        learning_rate_base {float} -- base learning rate.\n","        total_steps {int} -- total number of training steps.\n","\n","    Keyword Arguments:\n","        global_step_init {int} -- initial global step, e.g. from previous checkpoint.\n","        warmup_learning_rate {float} -- initial learning rate for warm up. (default: {0.0})\n","        warmup_steps {int} -- number of warmup steps. (default: {0})\n","        hold_base_rate_steps {int} -- Optional number of steps to hold base learning rate\n","                                    before decaying. (default: {0})\n","        verbose {int} -- 0: quiet, 1: update messages. (default: {0})\n","        \"\"\"\n","\n","        super(WarmUpCosineDecayScheduler, self).__init__()\n","        self.learning_rate_base = learning_rate_base\n","        self.total_steps = total_steps\n","        self.global_step = global_step_init\n","        self.warmup_learning_rate = warmup_learning_rate\n","        self.warmup_steps = warmup_steps\n","        self.hold_base_rate_steps = hold_base_rate_steps\n","        self.verbose = verbose\n","        self.learning_rates = []\n","\n","    def on_batch_end(self, batch, logs=None):\n","        self.global_step = self.global_step + 1\n","        lr = K.get_value(self.model.optimizer.lr)\n","        self.learning_rates.append(lr)\n","\n","    def on_batch_begin(self, batch, logs=None):\n","        lr = cosine_decay_with_warmup(global_step=self.global_step,\n","                                      learning_rate_base=self.learning_rate_base,\n","                                      total_steps=self.total_steps,\n","                                      warmup_learning_rate=self.warmup_learning_rate,\n","                                      warmup_steps=self.warmup_steps,\n","                                      hold_base_rate_steps=self.hold_base_rate_steps)\n","        K.set_value(self.model.optimizer.lr, lr)\n","        if self.verbose > 0:\n","            print('\\nBatch %05d: setting learning '\n","                  'rate to %s.' % (self.global_step + 1, lr))\n","\n","\n","warm_up_lr = WarmUpCosineDecayScheduler(learning_rate_base=initial_lr,\n","                                        total_steps = int(epochs * sample_count / batch_size),\n","                                        warmup_learning_rate = initial_lr,\n","                                        warmup_steps = int(warmup_epoch * sample_count / batch_size),\n","                                        hold_base_rate_steps=0)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Sh46GIfxABza","colab_type":"text"},"source":["#### Label Smoothing"]},{"cell_type":"code","metadata":{"id":"iqW8G8oXAAcN","colab_type":"code","colab":{}},"source":["def smooth_labels(y, smooth_factor):\n","    '''Convert a matrix of one-hot row-vector labels into smoothed versions.\n","\n","    # Arguments\n","        y: matrix of one-hot row-vector labels to be smoothed\n","        smooth_factor: label smoothing factor (between 0 and 1)\n","\n","    # Returns\n","        A matrix of smoothed labels.\n","    '''\n","    assert len(y.shape) == 2\n","    if 0 <= smooth_factor <= 1:\n","        # label smoothing ref: https://www.robots.ox.ac.uk/~vgg/rg/papers/reinception.pdf\n","        y *= 1 - smooth_factor\n","        y += smooth_factor / y.shape[1]\n","    else:\n","        raise Exception(\n","            'Invalid label smoothing factor: ' + str(smooth_factor))\n","    return y"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HnC9691RARjb","colab_type":"code","outputId":"46d159a3-0dc7-4e98-ec12-8a9ecb1e477b","executionInfo":{"status":"ok","timestamp":1565976739010,"user_tz":420,"elapsed":51007,"user":{"displayName":"Kilean Hwang","photoUrl":"","userId":"05193167569663589626"}},"colab":{"base_uri":"https://localhost:8080/","height":71}},"source":["print('Before smoothing: {}'.format(train_data['y'][0]))\n","smooth_labels(train_data['y'], .02)\n","print('After smoothing: {}'.format(train_data['y'][0]))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Before smoothing: [1. 0. 0. 0. 0. 0. 0.]\n","After smoothing: [0.98285717 0.00285714 0.00285714 0.00285714 0.00285714 0.00285714\n"," 0.00285714]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"VNg4Y_l3eL0X","colab_type":"text"},"source":["### Train"]},{"cell_type":"code","metadata":{"id":"SShd22ukEH0H","colab_type":"code","colab":{}},"source":["check_point = keras.callbacks.ModelCheckpoint(data_path+'ResNet50_48x48.cosDecay.LabelSmoothing.resnet-C.epoch={epoch:02d}.acc={acc:.2f}.val_acc={val_acc:.2f}.hdf5', monitor='val_loss', verbose=0, \n","                                              save_best_only=True, save_weights_only=False, mode='auto', period=1)\n","stopping = keras.callbacks.EarlyStopping(monitor='val_loss',patience=15)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4KBNi0Ex3Nep","colab_type":"code","outputId":"6222ac3f-be20-48da-e8f8-bbe2a7c393a0","executionInfo":{"status":"ok","timestamp":1565985451386,"user_tz":420,"elapsed":358267,"user":{"displayName":"Kilean Hwang","photoUrl":"","userId":"05193167569663589626"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n","\n","history = model.fit(train_data['x'], train_data['y'],\n","                    validation_data=(public_test_data['x'], public_test_data['y']),\n","                    epochs = 50, batch_size = 128, callbacks=[check_point,stopping,warm_up_lr])\n","\n","with open(data_path+'ResNet50_48x48.cosDecay.LabelSmoothing.resnet-C.hist.pickle','wb') as f:\n","  pickle.dump(history,f)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["W0816 17:32:18.903377 139952381024128 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n","W0816 17:32:19.095123 139952381024128 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n"],"name":"stderr"},{"output_type":"stream","text":["Train on 28709 samples, validate on 3589 samples\n","Epoch 1/50\n","28709/28709 [==============================] - 314s 11ms/step - loss: 1.8848 - acc: 0.2480 - val_loss: 1.8003 - val_acc: 0.2494\n","Epoch 2/50\n","28709/28709 [==============================] - 288s 10ms/step - loss: 1.8303 - acc: 0.2457 - val_loss: 11.8036 - val_acc: 0.2494\n","Epoch 3/50\n","28709/28709 [==============================] - 288s 10ms/step - loss: 1.8140 - acc: 0.2480 - val_loss: 2.4586 - val_acc: 0.1875\n","Epoch 4/50\n","28709/28709 [==============================] - 288s 10ms/step - loss: 1.7798 - acc: 0.2652 - val_loss: 1.8253 - val_acc: 0.2538\n","Epoch 5/50\n","28709/28709 [==============================] - 287s 10ms/step - loss: 1.7372 - acc: 0.2931 - val_loss: 3.0418 - val_acc: 0.1301\n","Epoch 6/50\n","28709/28709 [==============================] - 289s 10ms/step - loss: 1.6204 - acc: 0.3614 - val_loss: 1.7284 - val_acc: 0.2998\n","Epoch 7/50\n","28709/28709 [==============================] - 290s 10ms/step - loss: 1.5085 - acc: 0.4176 - val_loss: 1.6446 - val_acc: 0.3761\n","Epoch 8/50\n","28709/28709 [==============================] - 289s 10ms/step - loss: 1.4221 - acc: 0.4582 - val_loss: 1.5474 - val_acc: 0.4216\n","Epoch 9/50\n","28709/28709 [==============================] - 289s 10ms/step - loss: 1.3576 - acc: 0.4893 - val_loss: 1.6502 - val_acc: 0.4101\n","Epoch 10/50\n","28709/28709 [==============================] - 289s 10ms/step - loss: 1.2944 - acc: 0.5167 - val_loss: 1.4642 - val_acc: 0.4514\n","Epoch 11/50\n","28709/28709 [==============================] - 289s 10ms/step - loss: 1.2380 - acc: 0.5446 - val_loss: 1.4899 - val_acc: 0.4759\n","Epoch 12/50\n","28709/28709 [==============================] - 290s 10ms/step - loss: 1.1822 - acc: 0.5674 - val_loss: 1.2821 - val_acc: 0.5188\n","Epoch 13/50\n","28709/28709 [==============================] - 289s 10ms/step - loss: 1.1313 - acc: 0.5921 - val_loss: 1.3575 - val_acc: 0.4940\n","Epoch 14/50\n","28709/28709 [==============================] - 289s 10ms/step - loss: 1.0808 - acc: 0.6141 - val_loss: 1.2515 - val_acc: 0.5375\n","Epoch 15/50\n","28709/28709 [==============================] - 289s 10ms/step - loss: 1.0388 - acc: 0.6313 - val_loss: 1.2050 - val_acc: 0.5472\n","Epoch 16/50\n","28709/28709 [==============================] - 289s 10ms/step - loss: 0.9755 - acc: 0.6574 - val_loss: 1.3103 - val_acc: 0.5060\n","Epoch 17/50\n","28709/28709 [==============================] - 289s 10ms/step - loss: 0.9162 - acc: 0.6838 - val_loss: 1.3323 - val_acc: 0.5174\n","Epoch 18/50\n","28709/28709 [==============================] - 288s 10ms/step - loss: 0.8456 - acc: 0.7149 - val_loss: 1.3283 - val_acc: 0.5261\n","Epoch 19/50\n","28709/28709 [==============================] - 288s 10ms/step - loss: 0.7775 - acc: 0.7430 - val_loss: 1.2897 - val_acc: 0.5436\n","Epoch 20/50\n","28709/28709 [==============================] - 288s 10ms/step - loss: 0.6881 - acc: 0.7827 - val_loss: 1.3671 - val_acc: 0.5425\n","Epoch 21/50\n","28709/28709 [==============================] - 289s 10ms/step - loss: 0.5967 - acc: 0.8187 - val_loss: 1.3543 - val_acc: 0.5525\n","Epoch 22/50\n","28709/28709 [==============================] - 288s 10ms/step - loss: 0.4954 - acc: 0.8601 - val_loss: 1.7221 - val_acc: 0.5085\n","Epoch 23/50\n","28709/28709 [==============================] - 287s 10ms/step - loss: 0.4097 - acc: 0.8957 - val_loss: 1.5937 - val_acc: 0.5748\n","Epoch 24/50\n","28709/28709 [==============================] - 287s 10ms/step - loss: 0.3263 - acc: 0.9303 - val_loss: 1.5821 - val_acc: 0.5606\n","Epoch 25/50\n","28709/28709 [==============================] - 288s 10ms/step - loss: 0.2667 - acc: 0.9538 - val_loss: 1.7993 - val_acc: 0.5489\n","Epoch 26/50\n","28709/28709 [==============================] - 288s 10ms/step - loss: 0.2141 - acc: 0.9753 - val_loss: 1.6162 - val_acc: 0.5876\n","Epoch 27/50\n","28709/28709 [==============================] - 288s 10ms/step - loss: 0.1781 - acc: 0.9885 - val_loss: 1.6042 - val_acc: 0.6030\n","Epoch 28/50\n","28709/28709 [==============================] - 287s 10ms/step - loss: 0.1598 - acc: 0.9932 - val_loss: 1.5381 - val_acc: 0.5999\n","Epoch 29/50\n","28709/28709 [==============================] - 288s 10ms/step - loss: 0.1509 - acc: 0.9956 - val_loss: 1.5554 - val_acc: 0.5963\n","Epoch 30/50\n","28709/28709 [==============================] - 289s 10ms/step - loss: 0.1461 - acc: 0.9965 - val_loss: 1.5706 - val_acc: 0.5965\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"WlsjXo3jLIRT","colab_type":"code","colab":{}},"source":["import matplotlib.pyplot as plt"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"sY8BtkKL4sX4","colab_type":"code","colab":{}},"source":["with open(data_path+'ResNet50_48x48.hist.pickle','rb') as f:\n","  hist = pickle.load(f)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"CSy2qnW-K9Pa","colab_type":"code","outputId":"9d80d9a5-1e3e-42d1-b2b5-8f8b176f99f8","executionInfo":{"status":"ok","timestamp":1565985501160,"user_tz":420,"elapsed":448,"user":{"displayName":"Kilean Hwang","photoUrl":"","userId":"05193167569663589626"}},"colab":{"base_uri":"https://localhost:8080/","height":233}},"source":["plt.figure(figsize=(8,3))\n","plt.subplot(1,2,1)\n","plt.plot(hist.history['loss'])\n","plt.plot(hist.history['val_loss'])\n","plt.subplot(1,2,2)\n","plt.plot(hist.history['acc'])\n","plt.plot(hist.history['val_acc'])"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[<matplotlib.lines.Line2D at 0x7f487ba4b828>]"]},"metadata":{"tags":[]},"execution_count":20},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAd0AAADGCAYAAACXW1qCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n","text/plain":["<Figure size 576x216 with 2 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"wcMkDX1vKtCD","colab_type":"code","colab":{}},"source":["with open(data_path+'ResNet50_48x48.cosDecay.hist.pickle','rb') as f:\n","  hist = pickle.load(f)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"phdkuer1Lfbe","colab_type":"code","outputId":"577e5418-7abc-45e6-e70d-848d1b590719","executionInfo":{"status":"ok","timestamp":1565985555177,"user_tz":420,"elapsed":538,"user":{"displayName":"Kilean Hwang","photoUrl":"","userId":"05193167569663589626"}},"colab":{"base_uri":"https://localhost:8080/","height":232}},"source":["plt.figure(figsize=(8,3))\n","plt.subplot(1,2,1)\n","plt.plot(hist.history['loss'])\n","plt.plot(hist.history['val_loss'])\n","plt.subplot(1,2,2)\n","plt.plot(hist.history['acc'])\n","plt.plot(hist.history['val_acc'])"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[<matplotlib.lines.Line2D at 0x7f44cfaf7588>]"]},"metadata":{"tags":[]},"execution_count":22},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAeQAAADFCAYAAACFKYHeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n","text/plain":["<Figure size 576x216 with 2 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"nx3ABmckLsWX","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}