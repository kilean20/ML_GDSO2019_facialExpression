{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"resnet50_48x48.improving.augmentation.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"CnzwnPKGJSRq","colab_type":"text"},"source":["# Tweaked ResNet50  for 48x48x1 inputs\n","\n","Made few chages in the first convolution and pooling layer of ResNet50 such that initial infomation loss is avoided for small (48x48) size input image\n","\n","References:  \n","&nbsp;&nbsp;\\[1\\] [Resnet with Keras](https://github.com/priya-dwivedi/Deep-Learning/blob/master/resnet_keras/Residual_Networks_yourself.ipynb)  \n","&nbsp;&nbsp;\\[2\\] [Kaggle Facial Expression DataSet](https://www.kaggle.com/c/challenges-in-representation-learning-facial-expression-recognition-challenge) is of grayscale 48x48 size images"]},{"cell_type":"code","metadata":{"id":"DuPq8tMisAp0","colab_type":"code","colab":{}},"source":["import os\n","os.environ['TF_ENABLE_AUTO_MIXED_PRECISION'] = '1'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zrvnj3WyWmOw","colab_type":"code","outputId":"323f53e7-1354-4f3c-e0e8-d62bdb66872f","executionInfo":{"status":"ok","timestamp":1565999674314,"user_tz":420,"elapsed":3670,"user":{"displayName":"Kyung Hwang","photoUrl":"","userId":"14710802727472226956"}},"colab":{"base_uri":"https://localhost:8080/","height":33}},"source":["import numpy as np\n","import keras\n","regularizers = keras.regularizers\n","K = keras.backend\n","ImageDataGenerator = keras.preprocessing.image.ImageDataGenerator"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"O5orxmYAJ4jK","colab_type":"text"},"source":["### Define Residual(=Identity) Bock"]},{"cell_type":"code","metadata":{"id":"gytYH5r9W0mz","colab_type":"code","colab":{}},"source":["def identity_block(X, f, filters, stage, block):\n","    \"\"\"\n","    Implementation of the identity block as defined in Figure 3\n","    \n","    Arguments:\n","    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n","    f -- integer, specifying the shape of the middle CONV's window for the main path\n","    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n","    stage -- integer, used to name the layers, depending on their position in the network\n","    block -- string/character, used to name the layers, depending on their position in the network\n","    \n","    Returns:\n","    X -- output of the identity block, tensor of shape (n_H, n_W, n_C)\n","    \"\"\"\n","    \n","    # defining name basis\n","    conv_name_base = 'res' + str(stage) + block + '_branch'\n","    bn_name_base = 'bn' + str(stage) + block + '_branch'\n","    \n","    # Retrieve Filters\n","    F1, F2, F3 = filters\n","    \n","    # Save the input value. You'll need this later to add back to the main path. \n","    X_shortcut = X\n","    \n","    # First component of main path\n","    X = keras.layers.Conv2D(filters = F1, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2a', \n","                            kernel_initializer = keras.initializers.glorot_uniform(seed=0))(X)\n","    X = keras.layers.BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n","    X = keras.layers.Activation('relu')(X)\n","\n","    # Second component of main path (≈3 lines)\n","    X = keras.layers.Conv2D(filters = F2, kernel_size = (f, f), strides = (1,1), padding = 'same', name = conv_name_base + '2b', \n","                            kernel_initializer = keras.initializers.glorot_uniform(seed=0))(X)\n","    X = keras.layers.BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n","    X = keras.layers.Activation('relu')(X)\n","\n","    # Third component of main path (≈2 lines)\n","    X = keras.layers.Conv2D(filters = F3, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2c', \n","                            kernel_initializer = keras.initializers.glorot_uniform(seed=0))(X)\n","    X = keras.layers.BatchNormalization(gamma_initializer='zeros', axis = 3, name = bn_name_base + '2c')(X)\n","\n","\n","    # Final step: Add shortcut value to main path, and pass it through a RELU activation (≈2 lines)\n","    X = keras.layers.Add()([X, X_shortcut])\n","    X = keras.layers.Activation('relu')(X)\n","    \n","    \n","    return X"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"AV328DvMNlaf"},"source":["### Define Down-sampling(=Convolution) Bock"]},{"cell_type":"code","metadata":{"id":"qA4zR-P6XNjl","colab_type":"code","colab":{}},"source":["def convolutional_block(X, f, filters, stage, block, s = 2):\n","    \"\"\"\n","    Implementation of the convolutional block as defined in Figure 4\n","    \n","    Arguments:\n","    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n","    f -- integer, specifying the shape of the middle CONV's window for the main path\n","    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n","    stage -- integer, used to name the layers, depending on their position in the network\n","    block -- string/character, used to name the layers, depending on their position in the network\n","    s -- Integer, specifying the stride to be used\n","    \n","    Returns:\n","    X -- output of the convolutional block, tensor of shape (n_H, n_W, n_C)\n","    \"\"\"\n","    \n","    # defining name basis\n","    conv_name_base = 'res' + str(stage) + block + '_branch'\n","    bn_name_base = 'bn' + str(stage) + block + '_branch'\n","    \n","    # Retrieve Filters\n","    F1, F2, F3 = filters\n","    \n","    # Save the input value\n","    X_shortcut = X\n","\n","\n","    ##### MAIN PATH #####\n","    # First component of main path \n","    X = keras.layers.Conv2D(F1, (1, 1), strides = (s,s), name = conv_name_base + '2a', \n","                            kernel_initializer = keras.initializers.glorot_uniform(seed=0))(X)\n","    X = keras.layers.BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n","    X = keras.layers.Activation('relu')(X)\n","\n","    # Second component of main path (≈3 lines)\n","    X = keras.layers.Conv2D(filters = F2, kernel_size = (f, f), strides = (1,1), padding = 'same', name = conv_name_base + '2b', \n","                            kernel_initializer = keras.initializers.glorot_uniform(seed=0))(X)\n","    X = keras.layers.BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n","    X = keras.layers.Activation('relu')(X)\n","\n","\n","    # Third component of main path (≈2 lines)\n","    X = keras.layers.Conv2D(filters = F3, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2c', \n","                            kernel_initializer = keras.initializers.glorot_uniform(seed=0))(X)\n","    X = keras.layers.BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n","\n","\n","    ##### SHORTCUT PATH #### (≈2 lines)\n","    X_shortcut = keras.layers.Conv2D(filters = F3, kernel_size = (1, 1), strides = (s,s), padding = 'valid', name = conv_name_base + '1',\n","                        kernel_initializer = keras.initializers.glorot_uniform(seed=0))(X_shortcut)\n","    X_shortcut = keras.layers.BatchNormalization(axis = 3, name = bn_name_base + '1')(X_shortcut)\n","\n","    # Final step: Add shortcut value to main path, and pass it through a RELU activation (≈2 lines)\n","    X = keras.layers.Add()([X, X_shortcut])\n","    X = keras.layers.Activation('relu')(X)\n","    \n","    return X"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"74HTZZNZOrxo","colab_type":"text"},"source":["### Define ResNet50"]},{"cell_type":"code","metadata":{"id":"drJ13VdiiqmU","colab_type":"code","colab":{}},"source":["def get_resnet50_48x48(input_shape=(48, 48, 1), classes=7):\n","    \"\"\"\n","    Implementation of the popular ResNet50 the following architecture:\n","    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n","    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> TOPLAYER\n","\n","    Arguments:\n","    input_shape -- shape of the images of the dataset\n","    classes -- integer, number of classes\n","\n","    Returns:\n","    model -- a Model() instance in Keras\n","    \"\"\"\n","\n","    # Define the input as a tensor with shape input_shape\n","    X_input = keras.layers.Input(input_shape)\n","\n","    # Zero-Padding\n","    X = keras.layers.ZeroPadding2D((2, 2))(X_input)\n","\n","    # Stage 1\n","    X = keras.layers.Conv2D(64, (5, 5), strides=(1, 1), name='conv1', \n","\t\t                        kernel_initializer=keras.initializers.glorot_uniform(seed=0))(X)\n","    X = keras.layers.BatchNormalization(axis=3, name='bn_conv1')(X)\n","    X = keras.layers.Activation('relu')(X)\t\n","    # X = keras.layers.ZeroPadding2D((1, 1))(X)\n","\n","\n","    # Stage 2\n","    X = convolutional_block(X, f=3, filters=[64, 64, 256], stage=2, block='a', s=1)\n","    X = identity_block(X, 3, [64, 64, 256], stage=2, block='b')\n","    X = identity_block(X, 3, [64, 64, 256], stage=2, block='c')\n","\n","    ### START CODE HERE ###\n","\n","    # Stage 3 (≈4 lines)\n","    X = convolutional_block(X, f = 3, filters = [128, 128, 512], stage = 3, block='a', s = 2)\n","    X = identity_block(X, 3, [128, 128, 512], stage=3, block='b')\n","    X = identity_block(X, 3, [128, 128, 512], stage=3, block='c')\n","    X = identity_block(X, 3, [128, 128, 512], stage=3, block='d')\n","\n","    # Stage 4 (≈6 lines)\n","    X = convolutional_block(X, f = 3, filters = [256, 256, 1024], stage = 4, block='a', s = 2)\n","    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='b')\n","    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='c')\n","    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='d')\n","    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='e')\n","    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='f')\n","\n","    # Stage 5 (≈3 lines)\n","    X = convolutional_block(X, f = 3, filters = [512, 512, 2048], stage = 5, block='a', s = 2)\n","    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='b')\n","    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='c')\n","\n","    # AVGPOOL (≈1 line). Use \"X = AveragePooling2D(...)(X)\"\n","    # X = keras.layers.AveragePooling2D((2,2), name=\"avg_pool\")(X)\n","    # X = keras.layers.GlobalAveragePooling2D(name=\"avg_pool\")(X)\n","\n","    ### END CODE HERE ###\n","\n","    # Create model\n","    model = keras.models.Model(inputs = X_input, outputs = X, name='resnet50_48x48')\n","\n","    return model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"DatH3IEafXZU","colab_type":"code","outputId":"a52fc386-7836-42a7-dd66-154aa0ce5c09","executionInfo":{"status":"ok","timestamp":1565999680498,"user_tz":420,"elapsed":9653,"user":{"displayName":"Kyung Hwang","photoUrl":"","userId":"14710802727472226956"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["resnet50_48x48 = get_resnet50_48x48()\n","resnet50_48x48.summary()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING: Logging before flag parsing goes to stderr.\n","W0816 23:54:34.036292 140015394948992 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","W0816 23:54:34.055427 140015394948992 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","W0816 23:54:34.061743 140015394948992 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n","W0816 23:54:34.093579 140015394948992 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n","\n","W0816 23:54:34.094877 140015394948992 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n","\n","W0816 23:54:34.661571 140015394948992 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            (None, 48, 48, 1)    0                                            \n","__________________________________________________________________________________________________\n","zero_padding2d_1 (ZeroPadding2D (None, 52, 52, 1)    0           input_1[0][0]                    \n","__________________________________________________________________________________________________\n","conv1 (Conv2D)                  (None, 48, 48, 64)   1664        zero_padding2d_1[0][0]           \n","__________________________________________________________________________________________________\n","bn_conv1 (BatchNormalization)   (None, 48, 48, 64)   256         conv1[0][0]                      \n","__________________________________________________________________________________________________\n","activation_1 (Activation)       (None, 48, 48, 64)   0           bn_conv1[0][0]                   \n","__________________________________________________________________________________________________\n","res2a_branch2a (Conv2D)         (None, 48, 48, 64)   4160        activation_1[0][0]               \n","__________________________________________________________________________________________________\n","bn2a_branch2a (BatchNormalizati (None, 48, 48, 64)   256         res2a_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_2 (Activation)       (None, 48, 48, 64)   0           bn2a_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res2a_branch2b (Conv2D)         (None, 48, 48, 64)   36928       activation_2[0][0]               \n","__________________________________________________________________________________________________\n","bn2a_branch2b (BatchNormalizati (None, 48, 48, 64)   256         res2a_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_3 (Activation)       (None, 48, 48, 64)   0           bn2a_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res2a_branch2c (Conv2D)         (None, 48, 48, 256)  16640       activation_3[0][0]               \n","__________________________________________________________________________________________________\n","res2a_branch1 (Conv2D)          (None, 48, 48, 256)  16640       activation_1[0][0]               \n","__________________________________________________________________________________________________\n","bn2a_branch2c (BatchNormalizati (None, 48, 48, 256)  1024        res2a_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","bn2a_branch1 (BatchNormalizatio (None, 48, 48, 256)  1024        res2a_branch1[0][0]              \n","__________________________________________________________________________________________________\n","add_1 (Add)                     (None, 48, 48, 256)  0           bn2a_branch2c[0][0]              \n","                                                                 bn2a_branch1[0][0]               \n","__________________________________________________________________________________________________\n","activation_4 (Activation)       (None, 48, 48, 256)  0           add_1[0][0]                      \n","__________________________________________________________________________________________________\n","res2b_branch2a (Conv2D)         (None, 48, 48, 64)   16448       activation_4[0][0]               \n","__________________________________________________________________________________________________\n","bn2b_branch2a (BatchNormalizati (None, 48, 48, 64)   256         res2b_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_5 (Activation)       (None, 48, 48, 64)   0           bn2b_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res2b_branch2b (Conv2D)         (None, 48, 48, 64)   36928       activation_5[0][0]               \n","__________________________________________________________________________________________________\n","bn2b_branch2b (BatchNormalizati (None, 48, 48, 64)   256         res2b_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_6 (Activation)       (None, 48, 48, 64)   0           bn2b_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res2b_branch2c (Conv2D)         (None, 48, 48, 256)  16640       activation_6[0][0]               \n","__________________________________________________________________________________________________\n","bn2b_branch2c (BatchNormalizati (None, 48, 48, 256)  1024        res2b_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","add_2 (Add)                     (None, 48, 48, 256)  0           bn2b_branch2c[0][0]              \n","                                                                 activation_4[0][0]               \n","__________________________________________________________________________________________________\n","activation_7 (Activation)       (None, 48, 48, 256)  0           add_2[0][0]                      \n","__________________________________________________________________________________________________\n","res2c_branch2a (Conv2D)         (None, 48, 48, 64)   16448       activation_7[0][0]               \n","__________________________________________________________________________________________________\n","bn2c_branch2a (BatchNormalizati (None, 48, 48, 64)   256         res2c_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_8 (Activation)       (None, 48, 48, 64)   0           bn2c_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res2c_branch2b (Conv2D)         (None, 48, 48, 64)   36928       activation_8[0][0]               \n","__________________________________________________________________________________________________\n","bn2c_branch2b (BatchNormalizati (None, 48, 48, 64)   256         res2c_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_9 (Activation)       (None, 48, 48, 64)   0           bn2c_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res2c_branch2c (Conv2D)         (None, 48, 48, 256)  16640       activation_9[0][0]               \n","__________________________________________________________________________________________________\n","bn2c_branch2c (BatchNormalizati (None, 48, 48, 256)  1024        res2c_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","add_3 (Add)                     (None, 48, 48, 256)  0           bn2c_branch2c[0][0]              \n","                                                                 activation_7[0][0]               \n","__________________________________________________________________________________________________\n","activation_10 (Activation)      (None, 48, 48, 256)  0           add_3[0][0]                      \n","__________________________________________________________________________________________________\n","res3a_branch2a (Conv2D)         (None, 24, 24, 128)  32896       activation_10[0][0]              \n","__________________________________________________________________________________________________\n","bn3a_branch2a (BatchNormalizati (None, 24, 24, 128)  512         res3a_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_11 (Activation)      (None, 24, 24, 128)  0           bn3a_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res3a_branch2b (Conv2D)         (None, 24, 24, 128)  147584      activation_11[0][0]              \n","__________________________________________________________________________________________________\n","bn3a_branch2b (BatchNormalizati (None, 24, 24, 128)  512         res3a_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_12 (Activation)      (None, 24, 24, 128)  0           bn3a_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res3a_branch2c (Conv2D)         (None, 24, 24, 512)  66048       activation_12[0][0]              \n","__________________________________________________________________________________________________\n","res3a_branch1 (Conv2D)          (None, 24, 24, 512)  131584      activation_10[0][0]              \n","__________________________________________________________________________________________________\n","bn3a_branch2c (BatchNormalizati (None, 24, 24, 512)  2048        res3a_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","bn3a_branch1 (BatchNormalizatio (None, 24, 24, 512)  2048        res3a_branch1[0][0]              \n","__________________________________________________________________________________________________\n","add_4 (Add)                     (None, 24, 24, 512)  0           bn3a_branch2c[0][0]              \n","                                                                 bn3a_branch1[0][0]               \n","__________________________________________________________________________________________________\n","activation_13 (Activation)      (None, 24, 24, 512)  0           add_4[0][0]                      \n","__________________________________________________________________________________________________\n","res3b_branch2a (Conv2D)         (None, 24, 24, 128)  65664       activation_13[0][0]              \n","__________________________________________________________________________________________________\n","bn3b_branch2a (BatchNormalizati (None, 24, 24, 128)  512         res3b_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_14 (Activation)      (None, 24, 24, 128)  0           bn3b_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res3b_branch2b (Conv2D)         (None, 24, 24, 128)  147584      activation_14[0][0]              \n","__________________________________________________________________________________________________\n","bn3b_branch2b (BatchNormalizati (None, 24, 24, 128)  512         res3b_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_15 (Activation)      (None, 24, 24, 128)  0           bn3b_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res3b_branch2c (Conv2D)         (None, 24, 24, 512)  66048       activation_15[0][0]              \n","__________________________________________________________________________________________________\n","bn3b_branch2c (BatchNormalizati (None, 24, 24, 512)  2048        res3b_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","add_5 (Add)                     (None, 24, 24, 512)  0           bn3b_branch2c[0][0]              \n","                                                                 activation_13[0][0]              \n","__________________________________________________________________________________________________\n","activation_16 (Activation)      (None, 24, 24, 512)  0           add_5[0][0]                      \n","__________________________________________________________________________________________________\n","res3c_branch2a (Conv2D)         (None, 24, 24, 128)  65664       activation_16[0][0]              \n","__________________________________________________________________________________________________\n","bn3c_branch2a (BatchNormalizati (None, 24, 24, 128)  512         res3c_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_17 (Activation)      (None, 24, 24, 128)  0           bn3c_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res3c_branch2b (Conv2D)         (None, 24, 24, 128)  147584      activation_17[0][0]              \n","__________________________________________________________________________________________________\n","bn3c_branch2b (BatchNormalizati (None, 24, 24, 128)  512         res3c_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_18 (Activation)      (None, 24, 24, 128)  0           bn3c_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res3c_branch2c (Conv2D)         (None, 24, 24, 512)  66048       activation_18[0][0]              \n","__________________________________________________________________________________________________\n","bn3c_branch2c (BatchNormalizati (None, 24, 24, 512)  2048        res3c_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","add_6 (Add)                     (None, 24, 24, 512)  0           bn3c_branch2c[0][0]              \n","                                                                 activation_16[0][0]              \n","__________________________________________________________________________________________________\n","activation_19 (Activation)      (None, 24, 24, 512)  0           add_6[0][0]                      \n","__________________________________________________________________________________________________\n","res3d_branch2a (Conv2D)         (None, 24, 24, 128)  65664       activation_19[0][0]              \n","__________________________________________________________________________________________________\n","bn3d_branch2a (BatchNormalizati (None, 24, 24, 128)  512         res3d_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_20 (Activation)      (None, 24, 24, 128)  0           bn3d_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res3d_branch2b (Conv2D)         (None, 24, 24, 128)  147584      activation_20[0][0]              \n","__________________________________________________________________________________________________\n","bn3d_branch2b (BatchNormalizati (None, 24, 24, 128)  512         res3d_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_21 (Activation)      (None, 24, 24, 128)  0           bn3d_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res3d_branch2c (Conv2D)         (None, 24, 24, 512)  66048       activation_21[0][0]              \n","__________________________________________________________________________________________________\n","bn3d_branch2c (BatchNormalizati (None, 24, 24, 512)  2048        res3d_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","add_7 (Add)                     (None, 24, 24, 512)  0           bn3d_branch2c[0][0]              \n","                                                                 activation_19[0][0]              \n","__________________________________________________________________________________________________\n","activation_22 (Activation)      (None, 24, 24, 512)  0           add_7[0][0]                      \n","__________________________________________________________________________________________________\n","res4a_branch2a (Conv2D)         (None, 12, 12, 256)  131328      activation_22[0][0]              \n","__________________________________________________________________________________________________\n","bn4a_branch2a (BatchNormalizati (None, 12, 12, 256)  1024        res4a_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_23 (Activation)      (None, 12, 12, 256)  0           bn4a_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res4a_branch2b (Conv2D)         (None, 12, 12, 256)  590080      activation_23[0][0]              \n","__________________________________________________________________________________________________\n","bn4a_branch2b (BatchNormalizati (None, 12, 12, 256)  1024        res4a_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_24 (Activation)      (None, 12, 12, 256)  0           bn4a_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res4a_branch2c (Conv2D)         (None, 12, 12, 1024) 263168      activation_24[0][0]              \n","__________________________________________________________________________________________________\n","res4a_branch1 (Conv2D)          (None, 12, 12, 1024) 525312      activation_22[0][0]              \n","__________________________________________________________________________________________________\n","bn4a_branch2c (BatchNormalizati (None, 12, 12, 1024) 4096        res4a_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","bn4a_branch1 (BatchNormalizatio (None, 12, 12, 1024) 4096        res4a_branch1[0][0]              \n","__________________________________________________________________________________________________\n","add_8 (Add)                     (None, 12, 12, 1024) 0           bn4a_branch2c[0][0]              \n","                                                                 bn4a_branch1[0][0]               \n","__________________________________________________________________________________________________\n","activation_25 (Activation)      (None, 12, 12, 1024) 0           add_8[0][0]                      \n","__________________________________________________________________________________________________\n","res4b_branch2a (Conv2D)         (None, 12, 12, 256)  262400      activation_25[0][0]              \n","__________________________________________________________________________________________________\n","bn4b_branch2a (BatchNormalizati (None, 12, 12, 256)  1024        res4b_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_26 (Activation)      (None, 12, 12, 256)  0           bn4b_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res4b_branch2b (Conv2D)         (None, 12, 12, 256)  590080      activation_26[0][0]              \n","__________________________________________________________________________________________________\n","bn4b_branch2b (BatchNormalizati (None, 12, 12, 256)  1024        res4b_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_27 (Activation)      (None, 12, 12, 256)  0           bn4b_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res4b_branch2c (Conv2D)         (None, 12, 12, 1024) 263168      activation_27[0][0]              \n","__________________________________________________________________________________________________\n","bn4b_branch2c (BatchNormalizati (None, 12, 12, 1024) 4096        res4b_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","add_9 (Add)                     (None, 12, 12, 1024) 0           bn4b_branch2c[0][0]              \n","                                                                 activation_25[0][0]              \n","__________________________________________________________________________________________________\n","activation_28 (Activation)      (None, 12, 12, 1024) 0           add_9[0][0]                      \n","__________________________________________________________________________________________________\n","res4c_branch2a (Conv2D)         (None, 12, 12, 256)  262400      activation_28[0][0]              \n","__________________________________________________________________________________________________\n","bn4c_branch2a (BatchNormalizati (None, 12, 12, 256)  1024        res4c_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_29 (Activation)      (None, 12, 12, 256)  0           bn4c_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res4c_branch2b (Conv2D)         (None, 12, 12, 256)  590080      activation_29[0][0]              \n","__________________________________________________________________________________________________\n","bn4c_branch2b (BatchNormalizati (None, 12, 12, 256)  1024        res4c_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_30 (Activation)      (None, 12, 12, 256)  0           bn4c_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res4c_branch2c (Conv2D)         (None, 12, 12, 1024) 263168      activation_30[0][0]              \n","__________________________________________________________________________________________________\n","bn4c_branch2c (BatchNormalizati (None, 12, 12, 1024) 4096        res4c_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","add_10 (Add)                    (None, 12, 12, 1024) 0           bn4c_branch2c[0][0]              \n","                                                                 activation_28[0][0]              \n","__________________________________________________________________________________________________\n","activation_31 (Activation)      (None, 12, 12, 1024) 0           add_10[0][0]                     \n","__________________________________________________________________________________________________\n","res4d_branch2a (Conv2D)         (None, 12, 12, 256)  262400      activation_31[0][0]              \n","__________________________________________________________________________________________________\n","bn4d_branch2a (BatchNormalizati (None, 12, 12, 256)  1024        res4d_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_32 (Activation)      (None, 12, 12, 256)  0           bn4d_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res4d_branch2b (Conv2D)         (None, 12, 12, 256)  590080      activation_32[0][0]              \n","__________________________________________________________________________________________________\n","bn4d_branch2b (BatchNormalizati (None, 12, 12, 256)  1024        res4d_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_33 (Activation)      (None, 12, 12, 256)  0           bn4d_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res4d_branch2c (Conv2D)         (None, 12, 12, 1024) 263168      activation_33[0][0]              \n","__________________________________________________________________________________________________\n","bn4d_branch2c (BatchNormalizati (None, 12, 12, 1024) 4096        res4d_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","add_11 (Add)                    (None, 12, 12, 1024) 0           bn4d_branch2c[0][0]              \n","                                                                 activation_31[0][0]              \n","__________________________________________________________________________________________________\n","activation_34 (Activation)      (None, 12, 12, 1024) 0           add_11[0][0]                     \n","__________________________________________________________________________________________________\n","res4e_branch2a (Conv2D)         (None, 12, 12, 256)  262400      activation_34[0][0]              \n","__________________________________________________________________________________________________\n","bn4e_branch2a (BatchNormalizati (None, 12, 12, 256)  1024        res4e_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_35 (Activation)      (None, 12, 12, 256)  0           bn4e_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res4e_branch2b (Conv2D)         (None, 12, 12, 256)  590080      activation_35[0][0]              \n","__________________________________________________________________________________________________\n","bn4e_branch2b (BatchNormalizati (None, 12, 12, 256)  1024        res4e_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_36 (Activation)      (None, 12, 12, 256)  0           bn4e_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res4e_branch2c (Conv2D)         (None, 12, 12, 1024) 263168      activation_36[0][0]              \n","__________________________________________________________________________________________________\n","bn4e_branch2c (BatchNormalizati (None, 12, 12, 1024) 4096        res4e_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","add_12 (Add)                    (None, 12, 12, 1024) 0           bn4e_branch2c[0][0]              \n","                                                                 activation_34[0][0]              \n","__________________________________________________________________________________________________\n","activation_37 (Activation)      (None, 12, 12, 1024) 0           add_12[0][0]                     \n","__________________________________________________________________________________________________\n","res4f_branch2a (Conv2D)         (None, 12, 12, 256)  262400      activation_37[0][0]              \n","__________________________________________________________________________________________________\n","bn4f_branch2a (BatchNormalizati (None, 12, 12, 256)  1024        res4f_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_38 (Activation)      (None, 12, 12, 256)  0           bn4f_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res4f_branch2b (Conv2D)         (None, 12, 12, 256)  590080      activation_38[0][0]              \n","__________________________________________________________________________________________________\n","bn4f_branch2b (BatchNormalizati (None, 12, 12, 256)  1024        res4f_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_39 (Activation)      (None, 12, 12, 256)  0           bn4f_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res4f_branch2c (Conv2D)         (None, 12, 12, 1024) 263168      activation_39[0][0]              \n","__________________________________________________________________________________________________\n","bn4f_branch2c (BatchNormalizati (None, 12, 12, 1024) 4096        res4f_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","add_13 (Add)                    (None, 12, 12, 1024) 0           bn4f_branch2c[0][0]              \n","                                                                 activation_37[0][0]              \n","__________________________________________________________________________________________________\n","activation_40 (Activation)      (None, 12, 12, 1024) 0           add_13[0][0]                     \n","__________________________________________________________________________________________________\n","res5a_branch2a (Conv2D)         (None, 6, 6, 512)    524800      activation_40[0][0]              \n","__________________________________________________________________________________________________\n","bn5a_branch2a (BatchNormalizati (None, 6, 6, 512)    2048        res5a_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_41 (Activation)      (None, 6, 6, 512)    0           bn5a_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res5a_branch2b (Conv2D)         (None, 6, 6, 512)    2359808     activation_41[0][0]              \n","__________________________________________________________________________________________________\n","bn5a_branch2b (BatchNormalizati (None, 6, 6, 512)    2048        res5a_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_42 (Activation)      (None, 6, 6, 512)    0           bn5a_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res5a_branch2c (Conv2D)         (None, 6, 6, 2048)   1050624     activation_42[0][0]              \n","__________________________________________________________________________________________________\n","res5a_branch1 (Conv2D)          (None, 6, 6, 2048)   2099200     activation_40[0][0]              \n","__________________________________________________________________________________________________\n","bn5a_branch2c (BatchNormalizati (None, 6, 6, 2048)   8192        res5a_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","bn5a_branch1 (BatchNormalizatio (None, 6, 6, 2048)   8192        res5a_branch1[0][0]              \n","__________________________________________________________________________________________________\n","add_14 (Add)                    (None, 6, 6, 2048)   0           bn5a_branch2c[0][0]              \n","                                                                 bn5a_branch1[0][0]               \n","__________________________________________________________________________________________________\n","activation_43 (Activation)      (None, 6, 6, 2048)   0           add_14[0][0]                     \n","__________________________________________________________________________________________________\n","res5b_branch2a (Conv2D)         (None, 6, 6, 512)    1049088     activation_43[0][0]              \n","__________________________________________________________________________________________________\n","bn5b_branch2a (BatchNormalizati (None, 6, 6, 512)    2048        res5b_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_44 (Activation)      (None, 6, 6, 512)    0           bn5b_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res5b_branch2b (Conv2D)         (None, 6, 6, 512)    2359808     activation_44[0][0]              \n","__________________________________________________________________________________________________\n","bn5b_branch2b (BatchNormalizati (None, 6, 6, 512)    2048        res5b_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_45 (Activation)      (None, 6, 6, 512)    0           bn5b_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res5b_branch2c (Conv2D)         (None, 6, 6, 2048)   1050624     activation_45[0][0]              \n","__________________________________________________________________________________________________\n","bn5b_branch2c (BatchNormalizati (None, 6, 6, 2048)   8192        res5b_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","add_15 (Add)                    (None, 6, 6, 2048)   0           bn5b_branch2c[0][0]              \n","                                                                 activation_43[0][0]              \n","__________________________________________________________________________________________________\n","activation_46 (Activation)      (None, 6, 6, 2048)   0           add_15[0][0]                     \n","__________________________________________________________________________________________________\n","res5c_branch2a (Conv2D)         (None, 6, 6, 512)    1049088     activation_46[0][0]              \n","__________________________________________________________________________________________________\n","bn5c_branch2a (BatchNormalizati (None, 6, 6, 512)    2048        res5c_branch2a[0][0]             \n","__________________________________________________________________________________________________\n","activation_47 (Activation)      (None, 6, 6, 512)    0           bn5c_branch2a[0][0]              \n","__________________________________________________________________________________________________\n","res5c_branch2b (Conv2D)         (None, 6, 6, 512)    2359808     activation_47[0][0]              \n","__________________________________________________________________________________________________\n","bn5c_branch2b (BatchNormalizati (None, 6, 6, 512)    2048        res5c_branch2b[0][0]             \n","__________________________________________________________________________________________________\n","activation_48 (Activation)      (None, 6, 6, 512)    0           bn5c_branch2b[0][0]              \n","__________________________________________________________________________________________________\n","res5c_branch2c (Conv2D)         (None, 6, 6, 2048)   1050624     activation_48[0][0]              \n","__________________________________________________________________________________________________\n","bn5c_branch2c (BatchNormalizati (None, 6, 6, 2048)   8192        res5c_branch2c[0][0]             \n","__________________________________________________________________________________________________\n","add_16 (Add)                    (None, 6, 6, 2048)   0           bn5c_branch2c[0][0]              \n","                                                                 activation_46[0][0]              \n","__________________________________________________________________________________________________\n","activation_49 (Activation)      (None, 6, 6, 2048)   0           add_16[0][0]                     \n","==================================================================================================\n","Total params: 23,579,904\n","Trainable params: 23,526,784\n","Non-trainable params: 53,120\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Rl1U6DMkfart","colab_type":"code","colab":{}},"source":["# model = keras.applications.resnet50.ResNet50(weights='imagenet')\n","# model.summary()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2DaCeaD4eth8","colab_type":"text"},"source":["### Add subnet for classification"]},{"cell_type":"code","metadata":{"id":"-RkLvpnR2YsV","colab_type":"code","outputId":"fa6d871a-a699-4d0b-8ec5-71a83030ce91","executionInfo":{"status":"ok","timestamp":1565999685857,"user_tz":420,"elapsed":14944,"user":{"displayName":"Kyung Hwang","photoUrl":"","userId":"14710802727472226956"}},"colab":{"base_uri":"https://localhost:8080/","height":572}},"source":["model = keras.models.Sequential()\n","model.add(resnet50_48x48)\n","model.add(keras.layers.GlobalAveragePooling2D(name='global_ave_pool'))\n","model.add(keras.layers.Dense(units=2048,name='FC1'))\n","model.add(keras.layers.BatchNormalization())\n","model.add(keras.layers.Activation('relu'))\n","model.add(keras.layers.Dropout(0.25))\n","model.add(keras.layers.Dense(units=128,name='FC2'))\n","model.add(keras.layers.BatchNormalization())\n","model.add(keras.layers.Activation('relu'))\n","model.add(keras.layers.Dropout(0.25))\n","model.add(keras.layers.Dense(7, activation='softmax'))\n","model.summary()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["W0816 23:54:45.432798 140015394948992 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"],"name":"stderr"},{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","resnet50_48x48 (Model)       (None, 6, 6, 2048)        23579904  \n","_________________________________________________________________\n","global_ave_pool (GlobalAvera (None, 2048)              0         \n","_________________________________________________________________\n","FC1 (Dense)                  (None, 2048)              4196352   \n","_________________________________________________________________\n","batch_normalization_1 (Batch (None, 2048)              8192      \n","_________________________________________________________________\n","activation_50 (Activation)   (None, 2048)              0         \n","_________________________________________________________________\n","dropout_1 (Dropout)          (None, 2048)              0         \n","_________________________________________________________________\n","FC2 (Dense)                  (None, 128)               262272    \n","_________________________________________________________________\n","batch_normalization_2 (Batch (None, 128)               512       \n","_________________________________________________________________\n","activation_51 (Activation)   (None, 128)               0         \n","_________________________________________________________________\n","dropout_2 (Dropout)          (None, 128)               0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 7)                 903       \n","=================================================================\n","Total params: 28,048,135\n","Trainable params: 27,990,663\n","Non-trainable params: 57,472\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"tWz2B8fzfU7y","colab_type":"code","colab":{}},"source":["# model.add(keras.layers.Conv2D(filters=256),kernal_size=(3,3),name='classification_conv1')\n","# model.add(keras.layers.Activation('relu'))\n","# model.add(keras.layers.Conv2D(filters=256),kernal_size=(3,3),name='classification_conv2')\n","# model.add(keras.layers.Activation('relu'))\n","# model.add(keras.layers.Conv2D(filters=256),kernal_size=(3,3),name='classification_conv3')\n","# model.add(keras.layers.Activation('relu'))\n","# model.add(keras.layers.Conv2D(filters=256),kernal_size=(3,3),name='classification_conv4')\n","# model.add(keras.layers.Activation('relu'))\n","# model.add(keras.layers.Conv2D(filters=7*9),kernal_size=(3,3),name='classification_conv5')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GUux0axyeIy9","colab_type":"text"},"source":["### Load Dataset"]},{"cell_type":"code","metadata":{"id":"lnpLsLF0ejf9","colab_type":"code","outputId":"0974361a-76ea-49f9-90e2-0f1b33db3756","executionInfo":{"status":"ok","timestamp":1565999689549,"user_tz":420,"elapsed":18594,"user":{"displayName":"Kyung Hwang","photoUrl":"","userId":"14710802727472226956"}},"colab":{"base_uri":"https://localhost:8080/","height":33}},"source":["from google.colab import drive\n","drive.mount('/content/drive/', force_remount=True)\n","data_path = '/content/drive/My Drive/WorkSpace/MLstudy/GDSO2019/data/'"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SNyPSKsIeNNA","colab_type":"code","colab":{}},"source":["import pickle\n","with open(data_path+'FER2013.train_data.pickle','rb') as f:\n","  train_data = pickle.load(f)\n","with open(data_path+'FER2013.public_test_data.pickle','rb') as f:\n","  public_test_data = pickle.load(f)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"F7UMj4wVuGij","colab_type":"code","colab":{}},"source":["sample_count = len(train_data['y'])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"m5KBNYTbrjIe","colab_type":"text"},"source":["### Cos decay with warm-up"]},{"cell_type":"code","metadata":{"id":"9b8f5hRYrtdR","colab_type":"code","colab":{}},"source":["base_batch_size = 256\n","base_lr = 0.1\n","multiplier = 0.5\n","batch_size = int(base_batch_size * multiplier)\n","initial_lr = base_lr * multiplier\n","warmup_epoch = 3\n","epochs = 25"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"O3lXXDWmrg6u","colab_type":"code","colab":{}},"source":["def cosine_decay_with_warmup(global_step,\n","                             learning_rate_base,\n","                             total_steps,\n","                             warmup_learning_rate=0.0,\n","                             warmup_steps=0,\n","                             hold_base_rate_steps=0,\n","                             learning_rate_min = 0.001): \n","    \"\"\"Cosine decay schedule with warm up period.\n","\n","    Cosine annealing learning rate as described in:\n","      Loshchilov and Hutter, SGDR: Stochastic Gradient Descent with Warm Restarts.\n","      ICLR 2017. https://arxiv.org/abs/1608.03983\n","    In this schedule, the learning rate grows linearly from warmup_learning_rate\n","    to learning_rate_base for warmup_steps, then transitions to a cosine decay\n","    schedule.\n","\n","    Arguments:\n","        global_step {int} -- global step.\n","        learning_rate_base {float} -- base learning rate.\n","        total_steps {int} -- total number of training steps.\n","\n","    Keyword Arguments:\n","        warmup_learning_rate {float} -- initial learning rate for warm up. (default: {0.0})\n","        warmup_steps {int} -- number of warmup steps. (default: {0})\n","        hold_base_rate_steps {int} -- Optional number of steps to hold base learning rate\n","                                    before decaying. (default: {0})\n","    Returns:\n","      a float representing learning rate.\n","\n","    Raises:\n","      ValueError: if warmup_learning_rate is larger than learning_rate_base,\n","        or if warmup_steps is larger than total_steps.\n","    \"\"\"\n","\n","    if total_steps < warmup_steps:\n","        raise ValueError('total_steps must be larger or equal to '\n","                         'warmup_steps.')\n","    learning_rate = 0.5 * learning_rate_base * (1 + np.cos(\n","        np.pi *\n","        (global_step - warmup_steps - hold_base_rate_steps\n","         ) / float(total_steps - warmup_steps - hold_base_rate_steps))) + learning_rate_min\n","    if hold_base_rate_steps > 0:\n","        learning_rate = np.where(global_step > warmup_steps + hold_base_rate_steps,\n","                                 learning_rate, learning_rate_base)\n","    if warmup_steps > 0:\n","        if learning_rate_base + learning_rate_min < warmup_learning_rate:\n","            raise ValueError('learning_rate_base + learning_rate_min must be larger or equal to '\n","                             'warmup_learning_rate.')\n","        slope = (learning_rate_base + learning_rate_min - warmup_learning_rate) / warmup_steps\n","        warmup_rate = slope * global_step + warmup_learning_rate\n","        learning_rate = np.where(global_step < warmup_steps, warmup_rate,\n","                                 learning_rate)\n","    return np.where(global_step > total_steps, learning_rate_min, learning_rate) # keep learing after fully decayed (Kilean)\n","\n","\n","\n","class WarmUpCosineDecayScheduler(keras.callbacks.Callback):\n","    \"\"\"Cosine decay with warmup learning rate scheduler\n","    \"\"\"\n","\n","    def __init__(self,\n","                 learning_rate_base,\n","                 total_steps,\n","                 global_step_init=0,\n","                 warmup_learning_rate=0.0,\n","                 warmup_steps=0,\n","                 hold_base_rate_steps=0,\n","                 verbose=0):\n","        \"\"\"Constructor for cosine decay with warmup learning rate scheduler.\n","\n","    Arguments:\n","        learning_rate_base {float} -- base learning rate.\n","        total_steps {int} -- total number of training steps.\n","\n","    Keyword Arguments:\n","        global_step_init {int} -- initial global step, e.g. from previous checkpoint.\n","        warmup_learning_rate {float} -- initial learning rate for warm up. (default: {0.0})\n","        warmup_steps {int} -- number of warmup steps. (default: {0})\n","        hold_base_rate_steps {int} -- Optional number of steps to hold base learning rate\n","                                    before decaying. (default: {0})\n","        verbose {int} -- 0: quiet, 1: update messages. (default: {0})\n","        \"\"\"\n","\n","        super(WarmUpCosineDecayScheduler, self).__init__()\n","        self.learning_rate_base = learning_rate_base\n","        self.total_steps = total_steps\n","        self.global_step = global_step_init\n","        self.warmup_learning_rate = warmup_learning_rate\n","        self.warmup_steps = warmup_steps\n","        self.hold_base_rate_steps = hold_base_rate_steps\n","        self.verbose = verbose\n","        self.learning_rates = []\n","\n","    def on_batch_end(self, batch, logs=None):\n","        self.global_step = self.global_step + 1\n","        lr = K.get_value(self.model.optimizer.lr)\n","        self.learning_rates.append(lr)\n","\n","    def on_batch_begin(self, batch, logs=None):\n","        lr = cosine_decay_with_warmup(global_step=self.global_step,\n","                                      learning_rate_base=self.learning_rate_base,\n","                                      total_steps=self.total_steps,\n","                                      warmup_learning_rate=self.warmup_learning_rate,\n","                                      warmup_steps=self.warmup_steps,\n","                                      hold_base_rate_steps=self.hold_base_rate_steps)\n","        K.set_value(self.model.optimizer.lr, lr)\n","        if self.verbose > 0:\n","            print('\\nBatch %05d: setting learning '\n","                  'rate to %s.' % (self.global_step + 1, lr))\n","\n","\n","warm_up_lr = WarmUpCosineDecayScheduler(learning_rate_base=initial_lr,\n","                                        total_steps = int(epochs * sample_count / batch_size),\n","                                        warmup_learning_rate =initial_lr,\n","                                        warmup_steps = int(warmup_epoch * sample_count / batch_size),\n","                                        hold_base_rate_steps=0)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Sh46GIfxABza","colab_type":"text"},"source":["#### Label Smoothing"]},{"cell_type":"code","metadata":{"id":"iqW8G8oXAAcN","colab_type":"code","colab":{}},"source":["def smooth_labels(y, smooth_factor):\n","    '''Convert a matrix of one-hot row-vector labels into smoothed versions.\n","\n","    # Arguments\n","        y: matrix of one-hot row-vector labels to be smoothed\n","        smooth_factor: label smoothing factor (between 0 and 1)\n","\n","    # Returns\n","        A matrix of smoothed labels.\n","    '''\n","    assert len(y.shape) == 2\n","    if 0 <= smooth_factor <= 1:\n","        # label smoothing ref: https://www.robots.ox.ac.uk/~vgg/rg/papers/reinception.pdf\n","        y *= 1 - smooth_factor\n","        y += smooth_factor / y.shape[1]\n","    else:\n","        raise Exception(\n","            'Invalid label smoothing factor: ' + str(smooth_factor))\n","    return y"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HnC9691RARjb","colab_type":"code","outputId":"224e450a-36f5-435f-d517-f1f70d6bf333","executionInfo":{"status":"ok","timestamp":1565999690867,"user_tz":420,"elapsed":19829,"user":{"displayName":"Kyung Hwang","photoUrl":"","userId":"14710802727472226956"}},"colab":{"base_uri":"https://localhost:8080/","height":67}},"source":["print('Before smoothing: {}'.format(train_data['y'][0]))\n","smooth_labels(train_data['y'], .02)\n","print('After smoothing: {}'.format(train_data['y'][0]))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Before smoothing: [1. 0. 0. 0. 0. 0. 0.]\n","After smoothing: [0.98285717 0.00285714 0.00285714 0.00285714 0.00285714 0.00285714\n"," 0.00285714]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ljsS6Ihc1ZfP","colab_type":"text"},"source":["### flaot32 to float16"]},{"cell_type":"code","metadata":{"id":"J12wclMD1r1D","colab_type":"code","colab":{}},"source":["train_data['x'] = train_data['x'].astype(np.float16)\n","train_data['y'] = train_data['y'].astype(np.float16)\n","public_test_data['x'] = public_test_data['x'].astype(np.float16)\n","public_test_data['y'] = public_test_data['y'].astype(np.float16)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YVZbK5qO9u_P","colab_type":"text"},"source":["### Data Augmentation"]},{"cell_type":"code","metadata":{"id":"xKgzUSXC9uIO","colab_type":"code","colab":{}},"source":["data_gen = ImageDataGenerator( rotation_range=10,\n","                              width_shift_range=0.1,\n","                              height_shift_range=0.1,\n","                              shear_range=0.1,\n","                              zoom_range=0.1,\n","                              horizontal_flip=True,\n","                              # fill_mode='constant',\n","                              # cval = 0.0,\n","                              brightness_range = [0.9,1.1]\n","                              )"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"-GrkAEwnSc21","colab":{}},"source":["train_data_gen = data_gen.flow(train_data['x'], train_data['y'],batch_size=128)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VNg4Y_l3eL0X","colab_type":"text"},"source":["### Train"]},{"cell_type":"code","metadata":{"id":"SShd22ukEH0H","colab_type":"code","colab":{}},"source":["check_point = keras.callbacks.ModelCheckpoint(data_path+'ResNet50_48x48.cosDecay.LabelSmoothing.zeroGamma.augmentation.epoch={epoch:02d}.acc={acc:.2f}.val_acc={val_acc:.2f}.hdf5', monitor='val_loss', verbose=0, \n","                                              save_best_only=True, save_weights_only=False, mode='auto', period=1)\n","stopping = keras.callbacks.EarlyStopping(monitor='val_loss',patience=15)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4KBNi0Ex3Nep","colab_type":"code","outputId":"6f653bc6-e477-408f-a998-e92b0e4b257f","executionInfo":{"status":"error","timestamp":1565999754224,"user_tz":420,"elapsed":83147,"user":{"displayName":"Kyung Hwang","photoUrl":"","userId":"14710802727472226956"}},"colab":{"base_uri":"https://localhost:8080/","height":707}},"source":["model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n","\n","hist = model.fit_generator(train_data_gen, \n","                    validation_data=(public_test_data['x'], public_test_data['y']),\n","                    epochs = 50, steps_per_epoch = train_data_gen.n//train_data_gen.batch_size, callbacks=[check_point,stopping,warm_up_lr])\n","\n","with open(data_path+'ResNet50_48x48.cosDecay.LabelSmoothing.zeroGamma.augmentation.hist.pickle','wb') as f:\n","  pickle.dump(hist,f)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["W0816 23:54:51.269841 140015394948992 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n","W0816 23:54:51.509878 140015394948992 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/50\n"],"name":"stdout"},{"output_type":"error","ename":"ResourceExhaustedError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)","\u001b[0;32m<ipython-input-21-f67ee51661f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m hist = model.fit_generator(train_data_gen, \n\u001b[1;32m      4\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpublic_test_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpublic_test_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'y'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                     epochs = 50, steps_per_epoch = train_data_gen.n//train_data_gen.batch_size, callbacks=[check_point,stopping,warm_up_lr])\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'ResNet50_48x48.cosDecay.LabelSmoothing.zeroGamma.augmentation.hist.pickle'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mResourceExhaustedError\u001b[0m: 2 root error(s) found.\n  (0) Resource exhausted: OOM when allocating tensor with shape[128,6,6,512] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node training/Adam/gradients/zeros_49-0-1-TransposeNCHWToNHWC-LayoutOptimizer}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[loss/mul/_3059]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n  (1) Resource exhausted: OOM when allocating tensor with shape[128,6,6,512] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node training/Adam/gradients/zeros_49-0-1-TransposeNCHWToNHWC-LayoutOptimizer}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n0 successful operations.\n0 derived errors ignored."]}]},{"cell_type":"code","metadata":{"id":"WlsjXo3jLIRT","colab_type":"code","colab":{}},"source":["import matplotlib.pyplot as plt"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SWeqEWtKUm_Z","colab_type":"code","colab":{}},"source":["plt.figure(figsize=(8,3))\n","plt.subplot(1,2,1)\n","plt.plot(hist.history['loss'])\n","plt.plot(hist.history['val_loss'])\n","plt.subplot(1,2,2)\n","plt.plot(hist.history['acc'])\n","plt.plot(hist.history['val_acc'])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"sY8BtkKL4sX4","colab_type":"code","colab":{}},"source":["with open(data_path+'ResNet50_48x48.hist.pickle','rb') as f:\n","  hist = pickle.load(f)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"CSy2qnW-K9Pa","colab_type":"code","colab":{}},"source":["plt.figure(figsize=(8,3))\n","plt.subplot(1,2,1)\n","plt.plot(hist.history['loss'])\n","plt.plot(hist.history['val_loss'])\n","plt.subplot(1,2,2)\n","plt.plot(hist.history['acc'])\n","plt.plot(hist.history['val_acc'])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wcMkDX1vKtCD","colab_type":"code","colab":{}},"source":["with open(data_path+'ResNet50_48x48.cosDecay.hist.pickle','rb') as f:\n","  hist = pickle.load(f)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"phdkuer1Lfbe","colab_type":"code","colab":{}},"source":["plt.figure(figsize=(8,3))\n","plt.subplot(1,2,1)\n","plt.plot(hist.history['loss'])\n","plt.plot(hist.history['val_loss'])\n","plt.subplot(1,2,2)\n","plt.plot(hist.history['acc'])\n","plt.plot(hist.history['val_acc'])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"y6UBeWXln_km","colab":{}},"source":["with open(data_path+'ResNet50_48x48.cosDecay.LabelSmoothing.hist.pickle','rb') as f:\n","  hist = pickle.load(f)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"MFxssyBYn_ks","colab":{}},"source":["plt.figure(figsize=(8,3))\n","plt.subplot(1,2,1)\n","plt.plot(hist.history['loss'])\n","plt.plot(hist.history['val_loss'])\n","plt.subplot(1,2,2)\n","plt.plot(hist.history['acc'])\n","plt.plot(hist.history['val_acc'])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"nx3ABmckLsWX","colab_type":"code","colab":{}},"source":["with open(data_path+'ResNet50_48x48.cosDecay.LabelSmoothing.zeroGamma.hist.pickle','rb') as f:\n","  hist = pickle.load(f)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"UxuyDC6_o65_","colab_type":"code","colab":{}},"source":["plt.figure(figsize=(8,3))\n","plt.subplot(1,2,1)\n","plt.plot(hist.history['loss'])\n","plt.plot(hist.history['val_loss'])\n","plt.subplot(1,2,2)\n","plt.plot(hist.history['acc'])\n","plt.plot(hist.history['val_acc'])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Thx1xoD9VIRM","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}